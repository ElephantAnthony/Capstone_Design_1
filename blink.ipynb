{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2893bb17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7652\\58244135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__tf' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(__tf.version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41610f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b23c4e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'form'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7652\\3686072733.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mform\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'form'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import form as form\n",
    "import keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50430a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7652\\2790867008.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6572e6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7652\\2971697587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0a65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: You must give at least one requirement to install (see \"pip help install\")\n"
     ]
    }
   ],
   "source": [
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6c6091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "absl-py                 1.3.0\n",
      "aiohttp                 3.8.3\n",
      "aiosignal               1.2.0\n",
      "anyio                   3.5.0\n",
      "argon2-cffi             21.3.0\n",
      "argon2-cffi-bindings    21.2.0\n",
      "astunparse              1.6.3\n",
      "async-timeout           4.0.2\n",
      "asynctest               0.13.0\n",
      "attrs                   22.1.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.11.1\n",
      "bleach                  4.1.0\n",
      "blinker                 1.4\n",
      "brotlipy                0.7.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2022.12.7\n",
      "cffi                    1.15.1\n",
      "charset-normalizer      2.0.4\n",
      "click                   8.0.4\n",
      "colorama                0.4.6\n",
      "cryptography            39.0.1\n",
      "cycler                  0.11.0\n",
      "debugpy                 1.5.1\n",
      "decorator               5.1.1\n",
      "defusedxml              0.7.1\n",
      "entrypoints             0.4\n",
      "fastjsonschema          2.16.2\n",
      "flatbuffers             2.0\n",
      "flit_core               3.6.0\n",
      "fonttools               4.38.0\n",
      "frozenlist              1.3.3\n",
      "gast                    0.4.0\n",
      "google-auth             2.6.0\n",
      "google-auth-oauthlib    0.4.4\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.42.0\n",
      "gTTS                    2.3.1\n",
      "h5py                    3.7.0\n",
      "idna                    3.4\n",
      "importlib-metadata      4.11.3\n",
      "importlib-resources     5.2.0\n",
      "ipykernel               6.15.2\n",
      "ipython                 7.31.1\n",
      "ipython-genutils        0.2.0\n",
      "jedi                    0.18.1\n",
      "Jinja2                  3.1.2\n",
      "jsonschema              4.17.3\n",
      "jupyter_client          7.4.9\n",
      "jupyter_core            4.11.2\n",
      "jupyter-server          1.23.4\n",
      "jupyterlab-pygments     0.1.2\n",
      "keras                   2.10.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.4.4\n",
      "Markdown                3.4.1\n",
      "MarkupSafe              2.1.1\n",
      "matplotlib              3.5.3\n",
      "matplotlib-inline       0.1.6\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.3.1\n",
      "mkl-random              1.2.2\n",
      "mkl-service             2.4.0\n",
      "multidict               6.0.2\n",
      "nbclassic               0.5.2\n",
      "nbclient                0.5.13\n",
      "nbconvert               6.4.4\n",
      "nbformat                5.7.0\n",
      "nest-asyncio            1.5.6\n",
      "notebook                6.5.2\n",
      "notebook_shim           0.2.2\n",
      "numpy                   1.21.5\n",
      "oauthlib                3.2.1\n",
      "opt-einsum              3.3.0\n",
      "packaging               22.0\n",
      "pandocfilters           1.5.0\n",
      "parso                   0.8.3\n",
      "pickleshare             0.7.5\n",
      "Pillow                  9.5.0\n",
      "pip                     22.3.1\n",
      "pkgutil_resolve_name    1.3.10\n",
      "prometheus-client       0.14.1\n",
      "prompt-toolkit          3.0.36\n",
      "protobuf                3.20.3\n",
      "psutil                  5.9.0\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.21\n",
      "Pygments                2.11.2\n",
      "PyJWT                   2.4.0\n",
      "pyOpenSSL               23.0.0\n",
      "pyparsing               3.0.9\n",
      "pyrsistent              0.18.0\n",
      "PySocks                 1.7.1\n",
      "python-dateutil         2.8.2\n",
      "pywin32                 305.1\n",
      "pywinpty                2.0.10\n",
      "pyzmq                   23.2.0\n",
      "requests                2.28.1\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "scipy                   1.7.3\n",
      "Send2Trash              1.8.0\n",
      "setuptools              65.6.3\n",
      "six                     1.16.0\n",
      "sniffio                 1.2.0\n",
      "soupsieve               2.3.2.post1\n",
      "tensorboard             2.10.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.1\n",
      "tensorflow              2.10.0\n",
      "tensorflow-estimator    2.10.0\n",
      "termcolor               2.1.0\n",
      "terminado               0.17.1\n",
      "testpath                0.6.0\n",
      "tornado                 6.2\n",
      "traitlets               5.7.1\n",
      "typing_extensions       4.4.0\n",
      "urllib3                 1.26.14\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        0.58.0\n",
      "Werkzeug                2.2.2\n",
      "wheel                   0.38.4\n",
      "win-inet-pton           1.1.0\n",
      "wincertstore            0.2\n",
      "wrapt                   1.14.1\n",
      "yarl                    1.8.1\n",
      "zipp                    3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e408ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1eab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b9f505",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/x_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5184\\3399624124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset/x_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset/y_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset/x_val.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset/y_val.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/x_train.npy'"
     ]
    }
   ],
   "source": [
    "x_train = np.load('dataset/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('dataset/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('dataset/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('dataset/y_val.npy').astype(np.float32)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613aceaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'path/to/training/dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\3864497140.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         class_mode='binary')\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m test_generator = test_datagen.flow_from_directory(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1666\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1668\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1669\u001b[0m         )\n\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'path/to/training/dataset'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 경로\n",
    "train_data_dir = 'path/to/training/dataset'\n",
    "test_data_dir = 'path/to/test/dataset'\n",
    "\n",
    "# 이미지 사이즈\n",
    "img_width, img_height = 48, 48\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# 이미지 데이터 전처리\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.n // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=test_generator,\n",
    "          validation_steps=test_generator.n // batch_size)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('blink_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b23a38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\1007497757.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# CSV 파일 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'path/to/dataset.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('path/to/dataset.csv')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4f0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0 MB)\n",
      "     ---------------------------------------- 10.0/10.0 MB 9.4 MB/s eta 0:00:00\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     -------------------------------------- 502.3/502.3 kB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.3.5 pytz-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7da3d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\2859289221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# CSV 파일 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'path/to/dataset.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 데이터프레임 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('path/to/dataset.csv')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245d2115",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\2572624473.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# CSV 파일 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 데이터프레임 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135bfbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state                                              image\n",
      "0   open  [178, 179, 181, 180, 175, 171, 170, 168, 162, ...\n",
      "1   open  [67, 66, 65, 64, 62, 62, 61, 61, 60, 61, 61, 5...\n",
      "2   open  [80, 84, 90, 94, 97, 100, 103, 107, 108, 112, ...\n",
      "3   open  [83, 81, 80, 81, 82, 81, 79, 78, 79, 80, 81, 7...\n",
      "4  close  [121, 126, 131, 136, 140, 144, 146, 146, 151, ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/dataset.csv')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623a5a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\674855436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/x_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/y_train.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/x_val.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/y_val.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/y_val.npy').astype(np.float32)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f415f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182c4d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('Downloads/eye_blink_detector-master/eye_blink_detector-master/dataset/y_val.npy').astype(np.float32)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "131e272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_genrator = train_datagen.flow(\n",
    "    x = x_train, y = y_train,\n",
    "    batch_size = 32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cfb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_genrator = train_datagen.flow(\n",
    "    x = x_train, y = y_train,\n",
    "    batch_size = 32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x = x_val, y = y_val,\n",
    "    batch_size = 32,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9148e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(26, 34, 1))\n",
    "\n",
    "net = Conv2D(32, kernel_size = 3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(64, kernel_size = 3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size = 3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e806e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datatime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\1195607556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatatime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y_%m_%H_%M_%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.fit_generator(\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     callbacks= [\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datatime' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = datatime.datetime.now().strftime('%Y_%m_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator, epochs = 50, validation_data = val_generator,\n",
    "    callbacks= [\n",
    "        ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=Trye, mode='max',\n",
    "                       verbose=1),\n",
    "        RedueLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c43e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\2097384764.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model.fit_generator(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     callbacks= [\n\u001b[0;32m      6\u001b[0m         ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=Trye, mode='max',\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator, epochs = 50, validation_data = val_generator,\n",
    "    callbacks= [\n",
    "        ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=Trye, mode='max',\n",
    "                       verbose=1),\n",
    "        RedueLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1ee397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586, 26, 34, 1) (2586, 1)\n",
      "(288, 26, 34, 1) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a69826",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trye' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\2986792135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_genrator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     callbacks= [\n\u001b[1;32m----> 6\u001b[1;33m         ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=Trye, mode='max',\n\u001b[0m\u001b[0;32m      7\u001b[0m                        verbose=1),\n\u001b[0;32m      8\u001b[0m         \u001b[0mRedueLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Trye' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_genrator, epochs = 50, validation_data = val_generator,\n",
    "    callbacks= [\n",
    "        ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=Trye, mode='max',\n",
    "                       verbose=1),\n",
    "        RedueLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ae41be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RedueLROnPlateau' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\1361756927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=True, mode='max',\n\u001b[0;32m      7\u001b[0m                        verbose=1),\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mRedueLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     ]\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RedueLROnPlateau' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_genrator, epochs = 50, validation_data = val_generator,\n",
    "    callbacks= [\n",
    "        ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=True, mode='max',\n",
    "                       verbose=1),\n",
    "        RedueLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d951a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4187 - acc: 0.8105\n",
      "Epoch 1: val_acc improved from -inf to 0.89236, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 9s 82ms/step - loss: 0.4187 - acc: 0.8105 - val_loss: 0.2492 - val_acc: 0.8924 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2502 - acc: 0.8995\n",
      "Epoch 2: val_acc improved from 0.89236 to 0.93750, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 0.2502 - acc: 0.8995 - val_loss: 0.1468 - val_acc: 0.9375 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1891 - acc: 0.9374\n",
      "Epoch 3: val_acc improved from 0.93750 to 0.95139, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1891 - acc: 0.9374 - val_loss: 0.1190 - val_acc: 0.9514 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9536\n",
      "Epoch 4: val_acc improved from 0.95139 to 0.98611, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 6s 68ms/step - loss: 0.1440 - acc: 0.9536 - val_loss: 0.0643 - val_acc: 0.9861 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1096 - acc: 0.9660\n",
      "Epoch 5: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1096 - acc: 0.9660 - val_loss: 0.0465 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1110 - acc: 0.9652\n",
      "Epoch 6: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 5s 66ms/step - loss: 0.1110 - acc: 0.9652 - val_loss: 0.0658 - val_acc: 0.9757 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.9729\n",
      "Epoch 7: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0815 - acc: 0.9729 - val_loss: 0.0752 - val_acc: 0.9792 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0894 - acc: 0.9710\n",
      "Epoch 8: val_acc did not improve from 0.98611\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0894 - acc: 0.9710 - val_loss: 0.0464 - val_acc: 0.9861 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0699 - acc: 0.9783\n",
      "Epoch 9: val_acc improved from 0.98611 to 0.99306, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0699 - acc: 0.9783 - val_loss: 0.0267 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0672 - acc: 0.9780\n",
      "Epoch 10: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0672 - acc: 0.9780 - val_loss: 0.0358 - val_acc: 0.9896 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0533 - acc: 0.9841\n",
      "Epoch 11: val_acc did not improve from 0.99306\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0533 - acc: 0.9841 - val_loss: 0.0262 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.9780\n",
      "Epoch 12: val_acc improved from 0.99306 to 0.99653, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.0604 - acc: 0.9780 - val_loss: 0.0163 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0485 - acc: 0.9834\n",
      "Epoch 13: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0485 - acc: 0.9834 - val_loss: 0.0143 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0392 - acc: 0.9865\n",
      "Epoch 14: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0392 - acc: 0.9865 - val_loss: 0.0148 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0449 - acc: 0.9838\n",
      "Epoch 15: val_acc did not improve from 0.99653\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0449 - acc: 0.9838 - val_loss: 0.0199 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0355 - acc: 0.9884\n",
      "Epoch 16: val_acc improved from 0.99653 to 1.00000, saving model to models\\2023_05_18_10_16.h5\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0355 - acc: 0.9884 - val_loss: 0.0097 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0286 - acc: 0.9903\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0286 - acc: 0.9903 - val_loss: 0.0097 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0305 - acc: 0.9884\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0305 - acc: 0.9884 - val_loss: 0.0098 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0267 - acc: 0.9915\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0267 - acc: 0.9915 - val_loss: 0.0101 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0275 - acc: 0.9903\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0275 - acc: 0.9903 - val_loss: 0.0218 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9891\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0319 - acc: 0.9892 - val_loss: 0.0107 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0221 - acc: 0.9923\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0221 - acc: 0.9923 - val_loss: 0.0069 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0224 - acc: 0.9930\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0224 - acc: 0.9930 - val_loss: 0.0121 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0159 - acc: 0.9938\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0159 - acc: 0.9938 - val_loss: 0.0116 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0155 - acc: 0.9965\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0155 - acc: 0.9965 - val_loss: 0.0146 - val_acc: 0.9931 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0244 - acc: 0.9927\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0244 - acc: 0.9927 - val_loss: 0.0096 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0129 - acc: 0.9957\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.0057 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0089 - acc: 0.9973\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 59ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0041 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0086 - acc: 0.9969 - val_loss: 0.0082 - val_acc: 0.9965 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9973\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 56ms/step - loss: 0.0067 - acc: 0.9973 - val_loss: 0.0046 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 58ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0028 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0030 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0082 - acc: 0.9985\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 59ms/step - loss: 0.0082 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9973\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0067 - acc: 0.9973 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "81/81 [==============================] - 5s 64ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0049 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9954\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.0106 - acc: 0.9954 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 6s 69ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0031 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9981\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0029 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9992\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0041 - acc: 0.9992 - val_loss: 0.0027 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0052 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9988\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0050 - acc: 0.9988\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0026 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0028 - val_acc: 1.0000 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0044 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9981\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0036 - val_acc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9985\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 63ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0037 - val_acc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 60ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0029 - val_acc: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "81/81 [==============================] - 5s 62ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0032 - val_acc: 1.0000 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18233042088>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_genrator, epochs = 50, validation_data = val_generator,\n",
    "    callbacks= [\n",
    "        ModelCheckpoint('models/%s.h5' %(start_time), monitor='val_acc', save_best_only=True, mode='max',\n",
    "                       verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf1aba5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\1472568577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/%s.h5'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8340014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [6 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 36, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-5xs6crt0\\sklearn_e1fe6ae166e14c6098e086c30fb14772\\setup.py\", line 10, in <module>\n",
      "      LONG_DESCRIPTION = f.read()\n",
      "  UnicodeDecodeError: 'cp949' codec can't decode byte 0xe2 in position 2: illegal multibyte sequence\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b5585d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\USER\\anaconda3\\envs\\deep\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.01.10 |       haa95532_0         158 KB  anaconda\n",
      "    certifi-2022.12.7          |   py37haa95532_0         152 KB  anaconda\n",
      "    joblib-1.1.1               |   py37haa95532_0         407 KB  anaconda\n",
      "    openssl-1.1.1s             |       h2bbff1b_0         5.8 MB  anaconda\n",
      "    scikit-learn-1.0.2         |   py37hf11a4ad_1         6.8 MB  anaconda\n",
      "    threadpoolctl-2.2.0        |     pyh0d69192_0          16 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             anaconda/win-64::joblib-1.1.1-py37haa95532_0 None\n",
      "  scikit-learn       anaconda/win-64::scikit-learn-1.0.2-py37hf11a4ad_1 None\n",
      "  threadpoolctl      anaconda/noarch::threadpoolctl-2.2.0-pyh0d69192_0 None\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates                                 pkgs/main --> anaconda None\n",
      "  certifi                                         pkgs/main --> anaconda None\n",
      "  openssl              pkgs/main::openssl-1.1.1t-h2bbff1b_0 --> anaconda::openssl-1.1.1s-h2bbff1b_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "openssl-1.1.1s       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1s       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1s       | 5.8 MB    | #3         |  14% \n",
      "openssl-1.1.1s       | 5.8 MB    | ##1        |  22% \n",
      "openssl-1.1.1s       | 5.8 MB    | ###6       |  36% \n",
      "openssl-1.1.1s       | 5.8 MB    | #####4     |  54% \n",
      "openssl-1.1.1s       | 5.8 MB    | ######9    |  69% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########2  |  83% \n",
      "openssl-1.1.1s       | 5.8 MB    | #########5 |  96% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########## | 100% \n",
      "\n",
      "certifi-2022.12.7    | 152 KB    |            |   0% \n",
      "certifi-2022.12.7    | 152 KB    | ########## | 100% \n",
      "certifi-2022.12.7    | 152 KB    | ########## | 100% \n",
      "\n",
      "joblib-1.1.1         | 407 KB    |            |   0% \n",
      "joblib-1.1.1         | 407 KB    | 3          |   4% \n",
      "joblib-1.1.1         | 407 KB    | #5         |  16% \n",
      "joblib-1.1.1         | 407 KB    | ###9       |  39% \n",
      "joblib-1.1.1         | 407 KB    | ######2    |  63% \n",
      "joblib-1.1.1         | 407 KB    | ########## | 100% \n",
      "joblib-1.1.1         | 407 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-1.0.2   | 6.8 MB    |            |   0% \n",
      "scikit-learn-1.0.2   | 6.8 MB    |            |   0% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | 1          |   1% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | 3          |   3% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | 5          |   6% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | 8          |   9% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | #4         |  14% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | ##2        |  22% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | ###2       |  32% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | ####       |  40% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | #####3     |  53% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | ######5    |  65% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | #######9   |  79% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | #########2 |  92% \n",
      "scikit-learn-1.0.2   | 6.8 MB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.2.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "ca-certificates-2023 | 158 KB    |            |   0% \n",
      "ca-certificates-2023 | 158 KB    | ########## | 100% \n",
      "ca-certificates-2023 | 158 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Windows 64-bit packages of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "\n",
      "done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f6cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fe5a2cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1681576392.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_10120\\1681576392.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    improt sklearn\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "improt sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95f3501f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\1472568577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/%s.h5'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "155e6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     -------------------------------------- 293.3/293.3 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from seaborn) (3.5.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from seaborn) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d54591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 16ms/step\n",
      "test acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGdCAYAAACGtNCDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqQElEQVR4nO3deXxU9bnH8W+ATFrGAGFJBuSCUWQRFQ1LiBWopBTsRcFa7VVuEbTasAouYCrK5jUsNUETpAWUTayAqMQKosFqRQKyJVggCm1AJMmEkEiQQCZhzv2DOuYcAmTChBmcz7uv3+uV/M4yz/gq+vA8v985IZIMAQAA/Ec9fwcAAAACC8kBAAAwITkAAAAmJAcAAMCE5AAAAJiQHAAAABOSAwAAYEJyAAAATEgOAACASQN/B/C9U/sz/R0CEHDsne72dwhAQDpdkVen93cd+ZfP7mVrcY3P7nWpBExyAABAwHCf9ncEfkVbAQAAmFA5AADAynD7OwK/IjkAAMDKTXIAAACqMIK8csCaAwAAYELlAAAAK9oKAADAhLYCAADAD6gcAABgFeQPQSI5AADAirYCAADAD0gOAACwcrt9N7zQq1cvpaen6/DhwzIMQ4MGDTrnufPmzZNhGHr00UdN8xEREXrttdd07NgxlZSUaOHChbLb7V7FQXIAAICFYbh9Nrxht9uVnZ2tUaNGnfe8wYMHq2fPnjp8+PBZx5YvX67OnTurX79+GjhwoHr37q358+d7FQdrDgAACBDvv/++3n///fOe06pVK6Wmpqp///567733TMc6duyo22+/Xd26ddP27dslSWPGjNHatWv1xBNPKD8/v0ZxUDkAAMDKh20Fm82m8PBw07DZbLUKKyQkRMuWLdPs2bO1Z8+es47HxcWppKTEkxhIUkZGhtxut2JjY2v8OSQHAABYGW6fjcTERJWWlppGYmJircKaOHGiKisr9dJLL1V73OFwqLCw0DR3+vRpFRcXy+Fw1PhzaCsAAGDlw+ccJCUlKTk52TRXXl7u9X1iYmL06KOPKiYmxlehnROVAwAA6pDL5dLx48dNw+VyeX2fXr16KTIyUl9//bUqKipUUVGhq666Si+88IJyc3MlSQUFBYqMjDRdV79+fTVt2lQFBQU1/iwqBwAAWAXgQ5CWLVumjIwM09z69eu1bNkyLVq0SJKUmZmpiIgIxcTEaMeOHZKkvn37ql69etqyZUuNP4vkAAAAKz+9ldFut6tdu3ae36Ojo9WlSxcVFxfr0KFDKi4uNp1fUVGhgoICffXVV5KknJwcrVu3TgsWLFBCQoJCQ0OVlpamN954o8Y7FSTaCgAABIxu3bopKytLWVlZkqSUlBRlZWVp2rRpNb7HkCFDlJOTow0bNmjt2rXauHGjHnnkEa/iCJFkeHVFHTm1P9PfIQABx97pbn+HAASk0xV5dXr/U1984LN7/eSGX/rsXpcKbQUAAKz81FYIFLQVAACACZUDAAAsDMN3zzm4HJEcAABgFYBbGS8l2goAAMCEygEAAFZBviCR5AAAAKsgbyuQHAAAYOXDFy9djlhzAAAATKgcAABgRVsBAACYBPmCRNoKAADAhMoBAABWtBUAAIAJbQUAAIAfUDkAAMAqyCsHJAcAAFgE+1sZaSsAAAATKgcAAFjRVgAAACZsZQQAACZBXjlgzQEAADChcgAAgBVtBQAAYEJbAQAA4AdUDgAAsKKtAAAATGgrAAAA/IDKAQAAVkFeOSA5AADAKsjXHNBWAAAAJlQOAACwoq0AAABMgrytQHIAAIBVkFcOWHMAAABMqBwAAGBFWwEAAJjQVgAAAPgBlQMAAKyoHAAAABPD8N3wQq9evZSenq7Dhw/LMAwNGjTIc6xBgwaaMWOGdu3ape+++06HDx/WkiVL1LJlS9M9IiIi9Nprr+nYsWMqKSnRwoULZbfbvYqD5AAAgABht9uVnZ2tUaNGnXWsYcOGiomJ0fTp0xUTE6Nf//rX6tChg9LT003nLV++XJ07d1a/fv00cOBA9e7dW/Pnz/cqjhBJ3qU1deTU/kx/hwAEHHunu/0dAhCQTlfk1en9y15/1mf3anj/tFpdZxiGBg8erDVr1pzznG7dumnr1q1q06aNDh06pI4dO2rv3r3q1q2btm/fLknq37+/1q5dq9atWys/P79Gn03lAAAAK7fbd6MONW7cWG63W99++60kKS4uTiUlJZ7EQJIyMjLkdrsVGxtb4/uyIBEAgDpks9kUFhZmmisvL5fL5bqo+4aFhWnmzJn661//quPHj0uSHA6HCgsLTeedPn1axcXFcjgcNb43lQMAAKwMt89GYmKiSktLTSMxMfGiwmvQoIFWrlypkJAQjRgxwkdfusr9fX5HAAAudz5sByQlJSk5Odk0V15eXuv7fZ8YtG3bVn379vVUDSSpoKBAkZGRpvPr16+vpk2bqqCgoOafUevoAAD4sfJyC+L5uFyui24hfO/7xODaa6/VbbfdpuLiYtPxzMxMRUREKCYmRjt27JAk9e3bV/Xq1dOWLVtq/jk+iRYAAFw0u92udu3aeX6Pjo5Wly5dVFxcrPz8fL355puKiYnRwIEDVb9+fUVFRUmSiouLVVFRoZycHK1bt04LFixQQkKCQkNDlZaWpjfeeKPGOxUktjICAY2tjED16nwr46tP+uxeDR+cXeNz+/Tpo48//vis+cWLF2vKlCk6cOBAtdf9/Oc/1yeffCLpzEOQ0tLSdMcdd8jtdmv16tUaO3asTpw4UeM4qBwAAGDlp8cnf/LJJwoJCTnn8fMd+15JSYmGDBlyUXGwWwEAAJhQOQAAwMoI7hcvkRwAAGBhuANiOZ7f0FYAAAAmVA4AALDy04LEQEFyAACAVZCvOaCtAAAATKgcAABgFeQLEkkOAACwYs0BAAAwCfLkgDUHAADAhMoBAABWPnxl8+WI5OAysO2LHC1evU579x/QkeJvNWfSWPW9pWuNrt25+ys9ODFJ7a5qrVVp0+s0zg8+/Vxpy95SnrNIbVpFafyD96pX9y6SpIrKSqUtXa1Pt+7SNwWFCrc3VOxN12nc8HsV2SyiTuMCLtaIhAf0+GMj5HC00K5de/TouGe0dVuWv8NCXaKtgEB38lS5OkT/l/448ndeXVf63Qk9/cJ8xd503UXHsHXXXg0Y9vg5j2ft2aeJM+fprl/21srUaeobF6NHp7+ofQe+kSSdKndp7/6D+sN9d2pF6jQlTxqjA98UaOzUORcdG1CX7rnnTv1p9mRNfy5Z3WMHKHvXHq19b7latGjm79CAOkNycBno1b2LxjzwG8Xf0s2r655LW6Jf/TxON3Zsd9Yxt9uthSve1YDhj6v74N/rN6Mm6YONW2sd4/I1H+hnXW/Q8N/8Sle3aaXRQ+9Wp2uu0hvvZkiSwu0NNf/5CerfO1bRrVuqS8d2+uPI32nP/gPKLzxa688F6tr4Rx/Wwlde15KlK7V37z6NHPWUyspOaviw//F3aKhLbsN34zJEcvAj9c4H/9A3BYVKGDK42uMLV/5N7370mZ4ZPUxvz3tevxvcX3+c/Rdt+yKnVp+XnbNfsTd3Ns3d0vV6ZefsP+c13504qZCQEIVf0bBWnwnUtdDQUMXE3KgNH33qmTMMQxs+2qiePWvW2sNlynD7blyGvF5z0KxZMz344IOKi4uTw+GQJBUUFGjTpk1avHixioqKfB4kvHPwcIHmLF6lxbOeVoP69c867qqo0MIV72rB8xPVpdOZqkLrlpHasfsrrVr7d3W7oaPXn1lUckzNmjQyzTVr0lhFJceqPb/c5VLKohW6vU9PXdHwp15/HnApNG/eVA0aNFCh0/zvtcLCI+rY4Ro/RQXUPa+Sg27dumn9+vUqKytTRkaGvvrqK0lSVFSUxo4dq6eeekr9+/fX9u3bz3sfm82msLAwy2yIpMuz/BJITp9266lZf9bIIXfpqtaOas/5Os+pU+UuPfL0LNN8RWWlOl7d1vN77K8f8fzsdrvlqqg0zQ287RY9M2aY1zFWVFbqiaS5Mgxp0ugHvL4eAOrcZdoO8BWvkoPU1FStWrVKCQkJ1R7/85//rNTUVN1yyy3nvU9iYqKmTJlimqss/kanS77xJhxU48TJk9q9L1c5/zqopHnLJEluw5BhGLp54HD9+bkn9dOfnEnM5k597KydArbQH/4vUXV3wxdf/kspr67UqzMTPXP2Kn/jbx7RWEe/LTXd6+i3x9Q8orFprqKyUk8mzVV+4VEtTHqKqgECWlFRsSorKxUZ1dw0HxnZQgXOI36KCpeCEeS7FbxKDrp06aJhw4ad83hKSop27tx5wfskJSUpOTnZNHdk54fehIJzuKLhT7X65f8zza14b4M+z96rF/44Wlc6Wshwu2ULDVV+4dHzthDatIry/OwsKlaD+vVNc1V16dhOW7L26HeD+3vmNu/crS5VFkN+nxgczHPqlRlPqUmjK2r7NYFLoqKiQjt27FLf225Vevp6SVJISIj63narXp63yM/RAXXHq+SgoKBAPXr00Jdfflnt8R49esjpdF7wPi6XSy6XyzIb3CWc8yk7eUpf5/3wz/Ww84hy/nVQjcOvUMvIZnpx0Uo5j5bo+Sf+oHr16unaq1qbrm/auJHCbKGm+Qd+PUCzF7wut2EopvO1On7ipLL27JO94U816Be3eh3jkEG/1IMTk7TkrXXq3b2L1n2yRbv35erZMcMlnUkMHn8+TXv3H1TalPFyn3arqPhbSVLj8CsUGsojNxCYUl5coEWvpGj7jl3aunWnxo55WHb7T7V4yQp/h4a6RFuh5v70pz9p/vz56tq1qzZs2OBJBKKiohQfH6+HH35YTzzxRJ0EGsx278vVQ0/N8Pw+e8FfJUl3/uJWPffYwzpSckwFR4q9uufooXcronEjvbLyb5r6n4cSdWp3lX5/78BaxXjTdddqxoQEpS5drZcWv6k2V0bpxWce9SQkhUdL9PHmM1Wle0Y/Y7r2lRlPqfuNnWr1uUBdW7UqXS2aN9WUZ5+Qw9FC2dm79d8D/1eFhSy+/lG7THcZ+IrXqwDvvfdejR8/Xl27dlX9/6yEP336tLZv367k5GStWrWqVoGc2p9Zq+uAHzN7p7v9HQIQkE5X5NXp/b+ber/P7nXF5Nd9dq9Lxeta7sqVK7Vy5Uo1aNBAzZufWaRTVFSkyspKnwcHAAAuvVo3eisrK1VQUODLWAAACAzsVgAAACZBviCRxycDAAATKgcAAFgF+W4FkgMAAKxoKwAAAPyAygEAABa8WwEAAJjRVgAAAPgBlQMAAKyCvHJAcgAAgBVbGQEAgEmQVw5YcwAAAEyoHAAAYGEEeeWA5AAAAKsgTw5oKwAAABOSAwAArNxu3w0v9OrVS+np6Tp8+LAMw9CgQYPOOmfq1KnKy8tTWVmZPvzwQ7Vr1850PCIiQq+99pqOHTumkpISLVy4UHa73as4SA4AALByG74bXrDb7crOztaoUaOqPT5hwgSNHTtWCQkJio2N1YkTJ7R+/XqFhYV5zlm+fLk6d+6sfv36aeDAgerdu7fmz5/vVRwhkgKisXJqf6a/QwACjr3T3f4OAQhIpyvy6vT+pSMG+Oxejea9X6vrDMPQ4MGDtWbNGs9cXl6eXnjhBb3wwgtn7t2okZxOp4YNG6YVK1aoY8eO2rt3r7p166bt27dLkvr376+1a9eqdevWys/Pr9FnUzkAAMDKh5UDm82m8PBw07DZbF6HFB0drZYtWyojI8MzV1paqi1btiguLk6SFBcXp5KSEk9iIEkZGRlyu92KjY2t8WeRHAAAYGEYhs9GYmKiSktLTSMxMdHrmBwOhyTJ6XSa5p1Op+eYw+FQYWGh6fjp06dVXFzsOacm2MoIAEAdSkpKUnJysmmuvLzcT9HUDMkBAABWPnzOgcvlksvluuj7FBQUSJKioqI8P3//e1ZWluecyMhI03X169dX06ZNTddcCG0FAACs/LRb4Xxyc3OVn5+v+Ph4z1x4eLhiY2OVmXlmUX9mZqYiIiIUExPjOadv376qV6+etmzZUuPPonIAAICFvx6fbLfbTc8tiI6OVpcuXVRcXKxDhw5pzpw5mjRpkvbt26fc3FxNnz5deXl5eueddyRJOTk5WrdunRYsWKCEhASFhoYqLS1Nb7zxRo13KkgkBwAABIxu3brp448/9vyekpIiSVq8eLGGDx+uWbNmyW63a/78+WrSpIk2btyoAQMGmNYwDBkyRGlpadqwYYPcbrdWr16tsWPHehUHzzkAAhjPOQCqV9fPOfh2aF+f3avJ0o98dq9LhcoBAABW3j31+EeHBYkAAMCEygEAABb+WpAYKEgOAACwCvLkgLYCAAAwoXIAAIBVkC9IJDkAAMAi2Ncc0FYAAAAmVA4AALCirQAAAKoK9rYCyQEAAFZBXjlgzQEAADChcgAAgIUR5JUDkgMAAKyCPDmgrQAAAEyoHAAAYEFbAQAAmAV5ckBbAQAAmFA5AADAgrYCAAAwITkAAAAmwZ4csOYAAACYUDkAAMDKCPF3BH5FcgAAgAVtBQAAgCqoHAAAYGG4aSsAAIAqaCsAAABUQeUAAAALg90KAACgKtoKAAAAVVA5AADAgt0KAADAxDD8HYF/kRwAAGAR7JUD1hwAAAATKgcAAFgEe+WA5AAAAItgX3NAWwEAAJhQOQAAwCLY2wpUDgAAsDCMEJ8Nb9SrV0/Tpk3Tv//9b5WVlWn//v2aNGnSWedNnTpVeXl5Kisr04cffqh27dr56quficOndwMAALU2ceJEjRgxQqNHj1anTp00ceJETZgwQWPGjPGcM2HCBI0dO1YJCQmKjY3ViRMntH79eoWFhfksDtoKAABY+OvdCrfccovWrFmjtWvXSpIOHjyo++67Tz169PCcM27cOD333HNKT0+XJA0dOlROp1ODBw/WihUrfBIHlQMAACzcRojPhs1mU3h4uGnYbLZqP3fTpk2Kj4/XtddeK0m68cYbdeutt2rdunWSpOjoaLVs2VIZGRmea0pLS7VlyxbFxcX57PuTHAAAUIcSExNVWlpqGomJidWeO2PGDL3xxhvKycmRy+XSzp07NWfOHL3++uuSJIfDIUlyOp2m65xOp+eYL9BWAADAwtuFhOeTlJSk5ORk01x5eXm15957770aMmSI7r//fu3evVs33XST5syZo7y8PC1dutRnMV0IyQEAABa+3MrocrnkcrlqdO7s2bM1Y8YMz9qBf/7zn2rbtq0SExO1dOlSFRQUSJKioqI8P3//e1ZWls9ipq0AAICFYfhueKNhw4Zyu82rIU+fPq169c785zo3N1f5+fmKj4/3HA8PD1dsbKwyMzMv+nt/j8oBAAAB4t1339XTTz+tr7/+Wrt379bNN9+sxx57TK+++qrnnDlz5mjSpEnat2+fcnNzNX36dOXl5emdd97xWRwkBwAAWPjrCYljxozR9OnT9fLLLysyMlJ5eXn6y1/+omnTpnnOmTVrlux2u+bPn68mTZpo48aNGjBgwDnXMdRGiKSAeL3Eqf2+K4cAPxb2Tnf7OwQgIJ2uyKvT+38R/d8+u9cNue/57F6XCmsOAACACW0FAAAsfLmV8XJEcgAAgIW3uwx+bGgrAAAAEyoHAABYuGkrAACAqoJ9zQFtBQAAYELlAAAAi2BfkEhyAACABWsOAgRPggPOdjLvU3+HAAQkW4tr6vT+rDkAAACoImAqBwAABAraCgAAwCTI1yPSVgAAAGZUDgAAsKCtAAAATNitAAAAUAWVAwAALNz+DsDPSA4AALAwRFsBAADAg8oBAAAW7iB/0AHJAQAAFu4gbyuQHAAAYMGaAwAAgCqoHAAAYMFWRgAAYEJbAQAAoAoqBwAAWNBWAAAAJsGeHNBWAAAAJlQOAACwCPYFiSQHAABYuIM7N6CtAAAAzKgcAABgwbsVAACASZC/lJHkAAAAK7YyAgAAVEHlAAAAC3cIaw4AAEAVwb7mgLYCAAABpFWrVlq2bJmKiopUVlamXbt2qWvXrqZzpk6dqry8PJWVlenDDz9Uu3btfBoDyQEAABZuHw5vNGnSRJ999pkqKip0++2367rrrtPjjz+ukpISzzkTJkzQ2LFjlZCQoNjYWJ04cULr169XWFjYxXxlE9oKAABY+OsJiRMnTtShQ4f04IMPeuYOHDhgOmfcuHF67rnnlJ6eLkkaOnSonE6nBg8erBUrVvgkDioHAADUIZvNpvDwcNOw2WzVnnvnnXdq27ZtWrlypZxOp3bs2KHf//73nuPR0dFq2bKlMjIyPHOlpaXasmWL4uLifBYzyQEAABZuhfhsJCYmqrS01DQSExOr/dyrr75aI0aM0L59+9S/f3/NmzdPL730koYOHSpJcjgckiSn02m6zul0eo75Am0FAAAsfLlbISkpScnJyaa58vLyas+tV6+etm3bpqefflqSlJWVpeuvv14JCQlaunSpD6M6PyoHAADUIZfLpePHj5uGy+Wq9tz8/Hzt2bPHNLd37161adNGklRQUCBJioqKMp0TFRXlOeYLJAcAAFi4Q3w3vPHZZ5+pQ4cOprn27dvr4MGDkqTc3Fzl5+crPj7eczw8PFyxsbHKzMy86O/9PdoKAABY+OvdCikpKdq0aZMSExO1cuVK9ejRQ4888ogeeeQRzzlz5szRpEmTtG/fPuXm5mr69OnKy8vTO++847M4SA4AALDw1xMSt23bprvuuktJSUl69tlnlZubq3Hjxun111/3nDNr1izZ7XbNnz9fTZo00caNGzVgwIBzrmOojRAFyFMi64e28ncIQMA5mfepv0MAApKtxTV1ev9XWw3x2b0ezFvus3tdKlQOAACw8NdDkAIFyQEAABb+WnMQKNitAAAATKgcAABgEeyVA5IDAAAsjCBfc0BbAQAAmFA5AADAgrYCAAAwCfbkgLYCAAAwoXIAAIBFQDw62I9IDgAAsOAJiQAAwIQ1BwAAAFVQOQAAwCLYKwckBwAAWAT7gkTaCgAAwITKAQAAFuxWAAAAJsG+5oC2AgAAMKFyAACARbAvSCQ5AADAwh3k6QFtBQAAYELlAAAAi2BfkEhyAACARXA3FUgOAAA4S7BXDlhzAAAATKgcAABgwRMSAQCACVsZAQAAqqByAACARXDXDUgOAAA4C7sVAAAAqqByAACARbAvSCQ5AADAIrhTA9oKAADAgsoBAAAWwb4gkeQAAAAL1hwAAACT4E4NWHMAAAAsqBwAAGAR7GsOqBwAAGBh+PB/tTVx4kQZhqGUlBTPXFhYmNLS0lRUVKTjx4/rzTffVGRkpC++sgnJAQAAAaZbt276wx/+oOzsbNN8SkqK7rjjDt1zzz3q06ePWrVqpbfeesvnn09yAACAhduHw1t2u13Lly/Xww8/rJKSEs98o0aN9NBDD+mxxx7T3//+d+3YsUPDhw/Xz372M8XGxtb2q1aL5AAAAAu3DJ8Nm82m8PBw07DZbOf87Llz5+q9997Thg0bTPNdu3aVzWZTRkaGZ+7LL7/UwYMHFRcX59PvT3IAAEAdSkxMVGlpqWkkJiZWe+5vf/tbxcTEVHvc4XCovLxcx44dM807nU45HA6fxsxuBQAALHz5nIOkpCQlJyeb5srLy886r3Xr1nrxxRfVr1+/ao9fSiQH8BiR8IAef2yEHI4W2rVrjx4d94y2bsvyd1hAtbZlfaFFr7+pPTn7deRosV5MekbxvW855/mf79ilB8dMPGv+4/Tlat6saZ3Fuf6jT5W2YKkOFzjVtvWVGj9iuHrf0kOSVFFZqdT5S/Rp5jZ9k5evK+x29ex+s8YnDFdki2Z1FhMuzJdPSHS5XHK5XBc8r2vXroqKitKOHTs8cw0aNFDv3r01evRo9e/fX2FhYWrcuLGpehAVFaWCggKfxSvRVsB/3HPPnfrT7Mma/lyyuscOUPauPVr73nK14F9QCFAnT55Sh3ZX6+nHR3p13d/+ukAfpy/3jKYRTWodw+c7dumXdz9wzuM7v9ijCVNm6K6B/bVqUZr69orT2MTp2vfvA5KkU6fKtefLf+kPw+7TylfTNOf5STrw9TcaPXFqrWPC5WvDhg26/vrrddNNN3nG1q1btXz5ct10003atm2bXC6X4uPjPde0b99ebdu2VWZmpk9joXIASdL4Rx/Wwlde15KlKyVJI0c9pV/dHq/hw/5Hs2bP9XN0wNl6xXVXr7juXl/XNKKJGoVfUe0xt9utV15bpTfT16noaInatrlSCcPu0y9v61WrGF9buUY/i+2mB4f8RpI05pGhyty6Q6+/+a4mTxij8CvsWvji86Zr/vjYCN33+3HKLyhUS4fv96+jZvzxEKTvvvtOu3fvNs2dOHFCR48e9cy/8sorSk5OVnFxsUpLS5WamqpNmzZpy5YtPo2F5AAKDQ1VTMyNmjErzTNnGIY2fLRRPXt29WNkgO/9ZtgouSoq1C76Ko18aIhibuzsObZg2Qr9bf3f9eyTY9SmdSttz/qnnpo2WxFNGqv7zTd6/VnZu/fqgd/eZZq7JbarPvr03H/L++67MoWEhCg83O7158F3LubhRXVp/PjxcrvdWr16tcLCwrR+/XqNHOld9awmSA6g5s2bqkGDBip0FpnmCwuPqGOHa/wUFeBbLZo11bNPjlHnjtfKVVGh1e++rwdHT9TrC+boug7t5HK5tHDpCi14MUk3Xd9JkvRfV7bUjl27tWrNulolB0VHS9SsaYRprnnTCBUdLan2/PJyl1Lmvapf/aKPrrCTHPhToDw++bbbbjP9Xl5ertGjR2v06NF1+rk+Tw5at26tqVOn6qGHHjrnOTabTWFhYaa5SretRgs2AKA2otu2VnTb1p7fb77hOn1zOF9LV7ytGc8+qa+/ydfJU+V6eNwfTddVVFSqU/sfkuTuv/ihEuA+7ZarosI0N/CXfTV5whiv46uorNTjzzwvwzD0zJN1+y9+4EJ8nhw0bdpUDzzwwHmTg8TERE2ZMsU0N236C5o2Pbn6C1CnioqKVVlZqcio5qb5yMgWKnAe8VNUQN27vlMH7dx1ppdbdvKkJOnl2VMV1cL8ZyE0NNTz8+rFP6zB2bU7RynzXtWitFmeObu9oefn5s0idLTYXCUoKi5R82bmasL3iUGes1CvvjSDqkEACNS2wqXidXJwxx13nPf41VdffcF7VLfns9LNqnh/qaio0I4du9T3tluVnr5ekhQSEqK+t92ql+ct8nN0QN3J2fdvzzbGa65qI5stVPnOI+dtIbRp3crzc0FhkerXr2+aq6pL507avD1Lv6uy7iBz60516dzJ8/v3icHXh/L0auoMNWnc6GK/FnwgUNoK/uJ1cvDOO+/IMAyFhISc8xzDOH/GVd2ez/qh4d6GAh9KeXGBFr2Sou07dmnr1p0aO+Zh2e0/1eIlK/wdGlCtsrKT+vqbPM/vh/OcyvnqX2rcKFwtHZFKmbdIhUVHlfTME5KkZSve1pWtHGoX3VblLpdWp7+vz3dka37Kc5LO/I1/2H13a9ZL82W43br5xs767kSZdu7arSvsDTXoV/28jvF/7x2k4aMmaPFfV6v3LT20LuMT7c7ZpykTx0o6kxg89vT/ac9X+zV31lS53W4VHS2WJDVuFG6qWACXktfJQX5+vkaOHKn09PRqj3fp0kXbt2+/6MBwaa1ala4WzZtqyrNPyOFooezs3frvgf+rwsKiC18M+ME/c/aZHmo0K3W+JGnQ7b/Q/016XEVHi5XvLPQcr6is1OzUBSo8clQ/+UmY2l8TrYVznlePrl0854x5eKgimjTWwmUrdSivQI2usKtTh3Z6eOhvaxXjzTdcp5lTJip1/hK9+JfFatv6Sr2U9IyuvfoqSVLhkaP6+8bNks7soqjq1dSZ6hHj/SJI+Ib7An/J/bELkZdPiVyzZo2ysrI0efLkao/feOON2rlzp+rXr+9VIPVDqy/LAcHsZN6n/g4BCEi2FnW7k2pIm7sufFINLf/6bZ/d61LxunIwe/Zs2c+zWGb//v1nbb0AAACXD6+Tg40bN573eFlZmf7xj3/UOiAAAPzNl+9WuBzxECQAACyCfSsjL14CAAAmVA4AALDgOQcAAMCENQcAAMCENQcAAABVUDkAAMCCNQcAAMDkQu8I+rGjrQAAAEyoHAAAYMFuBQAAYBLsaw5oKwAAABMqBwAAWAT7cw5IDgAAsAj2NQe0FQAAgAmVAwAALIL9OQckBwAAWAT7bgWSAwAALIJ9QSJrDgAAgAmVAwAALIJ9twLJAQAAFsG+IJG2AgAAMKFyAACABW0FAABgwm4FAACAKqgcAABg4Q7yBYkkBwAAWAR3akBbAQAAWFA5AADAgt0KAADAhOQAAACY8IREAAAQEJ566il9/vnnKi0tldPp1Ntvv6327dubzgkLC1NaWpqKiop0/Phxvfnmm4qMjPRpHCQHAABYuGX4bHijT58+mjt3rnr27Kl+/fopNDRUH3zwgRo2bOg5JyUlRXfccYfuuece9enTR61atdJbb73l0+8fogDZsVE/tJW/QwACzsm8T/0dAhCQbC2uqdP7d2vZy2f32pZf+z/HzZs315EjR9S7d299+umnatSokY4cOaL7779fq1evliR16NBBOTk56tmzp7Zs2eKTmKkcAABQh2w2m8LDw03DZrPV6NrGjRtLkoqLiyVJXbt2lc1mU0ZGhuecL7/8UgcPHlRcXJzPYiY5AADAwjAMn43ExESVlpaaRmJi4gVjCAkJ0Zw5c7Rx40bt3r1bkuRwOFReXq5jx46ZznU6nXI4HD77/uxWAADAwpdbGZOSkpScnGyaKy8vv+B1c+fO1fXXX69bb73VZ7HUFMkBAAB1yOVyyeVyeXVNamqqBg4cqN69e+vw4cOe+YKCAoWFhalx48am6kFUVJQKCgp8FjNtBQAALHzZVvBWamqq7rrrLvXt21cHDhwwHdu+fbtcLpfi4+M9c+3bt1fbtm2VmZl5sV/bg8oBAAAW/npC4ty5c3X//fdr0KBBOn78uKKioiRJx44d06lTp1RaWqpXXnlFycnJKi4uVmlpqVJTU7Vp0yaf7VSQSA4AAAgYI0eOlCR98sknpvlhw4ZpyZIlkqTx48fL7XZr9erVCgsL0/r16z3X+QrPOQACGM85AKpX1885uCGqp8/u9YVzs8/udalQOQAAwMId5O9WIDkAAMDCCIyiut+wWwEAAJhQOQAAwIK2AgAAMKGtAAAAUAWVAwAALGgrAAAAE9oKAAAAVVA5AADAgrYCAAAwoa0AAABQBZUDAAAsDMPt7xD8iuQAAAALd5C3FUgOAACwMIJ8QSJrDgAAgAmVAwAALGgrAAAAE9oKAAAAVVA5AADAgickAgAAE56QCAAAUAWVAwAALIJ9QSLJAQAAFsG+lZG2AgAAMKFyAACABW0FAABgwlZGAABgEuyVA9YcAAAAEyoHAABYBPtuBZIDAAAsaCsAAABUQeUAAAALdisAAAATXrwEAABQBZUDAAAsaCsAAAATdisAAABUQeUAAAALFiQCAAATwzB8Nrw1cuRI5ebm6uTJk9q8ebO6d+9eB9/w/EgOAACw8FdycO+99yo5OVlTp05VTEyMsrOztX79erVo0aKOvmn1QqTAqJ3UD23l7xCAgHMy71N/hwAEJFuLa+r0/g18+N+kyoq8Gp+7efNmbd26VWPGjJEkhYSE6NChQ0pNTdXMmTN9FtOFUDkAAMDC8OGw2WwKDw83DZvNdtZnhoaGqmvXrsrIyPghDsNQRkaG4uLi6uy7nosv/xkwLvNhs9mMyZMnGzabze+xMBiBMvhzwbiYMXnyZMNq8uTJZ53XsmVLwzAMo2fPnqb5mTNnGps3b76kMQdMWwGBITw8XKWlpWrUqJGOHz/u73CAgMCfC1wMm82msLAw01x5eblcLpdprmXLlsrLy1NcXJw2b97smZ85c6b69Omjnj17XpJ4JbYyAgBQp1wu11mJQHWKiopUWVmpqKgo03xUVJQKCgrqKrxqseYAAIAAUFFRoe3btys+Pt4zFxISovj4eGVmZl7SWKgcAAAQIJKTk7VkyRJt27ZNn3/+ucaNGye73a5FixZd0jhIDmBSXl6uKVOmqLy83N+hAAGDPxe4VFauXKkWLVpo2rRpcjgcysrK0oABA1RYWHhJ42BBIgAAMGHNAQAAMCE5AAAAJiQHAADAhOQAAACYkBzAIxBeEwoEkl69eik9PV2HDx+WYRgaNGiQv0MCLgmSA0gKnNeEAoHEbrcrOztbo0aN8ncowCXn95dSMPw/Nm/ebKSmpnp+DwkJMb755htj4sSJfo+NwQiEYRiGMWjQIL/HwWBcikHlAAH3mlAAgH+RHEDNmzdXgwYN5HQ6TfNOp1MOh8NPUQEA/IXkAAAAmJAcIKBeEwoA8D+SAwTUa0IBAP7HWxkhKXBeEwoEErvdrnbt2nl+j46OVpcuXVRcXKxDhw75MTKg7vl9ywQjMMaoUaOMAwcOGKdOnTI2b95s9OjRw+8xMRj+HH369DGqs2jRIr/HxmDU5eCVzQAAwIQ1BwAAwITkAAAAmJAcAAAAE5IDAABgQnIAAABMSA4AAIAJyQEAADAhOQAAACYkBwAAwITkAAAAmJAcAAAAE5IDAABg8v8dR8LAC1sgWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20d10803",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\786965308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e76a52d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "709184ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "     ---------------------------------------- 38.2/38.2 MB 7.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\envs\\deep\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "781250a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [7 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  \n",
      "  ERROR: CMake must be installed to build dlib\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for dlib did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [9 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\setuptools\\command\\install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    setuptools.SetuptoolsDeprecationWarning,\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  \n",
      "  ERROR: CMake must be installed to build dlib\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "dlib\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading dlib-19.24.1.tar.gz (3.2 MB)\n",
      "     ---------------------------------------- 3.2/3.2 MB 10.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n",
      "Installing collected packages: dlib\n",
      "  Running setup.py install for dlib: started\n",
      "  Running setup.py install for dlib: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02836b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Downloading cmake-3.26.3-py2.py3-none-win_amd64.whl (33.0 MB)\n",
      "     --------------------------------------- 33.0/33.0 MB 11.3 MB/s eta 0:00:00\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.26.3\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c666126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.1.tar.gz (3.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.24.1-cp37-cp37m-win_amd64.whl size=2798221 sha256=4ad516ba0de82f1c0da6ddb8e8a3bdecd15fcb4fdf8918dc5b9a5b450f3e069a\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\be\\28\\ef\\be877f85f9760adadab2a51707ff31c835be8631e38866bad1\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.24.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8c0408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\786965308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdf63ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25854 sha256=b443dd8110e21f47407ab37de21ac76fd02eb8647073678925a6ef025e845c93\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\35\\e4\\69\\cb99d996d14a2971b79b990d68b05a17d58ce530ff96090dfc\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2c62764",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10120\\786965308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks(1).dat.bz2')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa10bd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2368\\3116047742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks(1).dat.bz2')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff86d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853604fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2368\\3116047742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks(1).dat.bz2')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6b4b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Using cached cmake-3.26.3-py2.py3-none-win_amd64.whl (33.0 MB)\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.26.3\n"
     ]
    }
   ],
   "source": [
    "!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56399f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.1.tar.gz (3.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n",
      "Installing collected packages: dlib\n",
      "  Running setup.py install for dlib: started\n",
      "  Running setup.py install for dlib: still running...\n",
      "  Running setup.py install for dlib: still running...\n",
      "  Running setup.py install for dlib: still running...\n",
      "  Running setup.py install for dlib: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [312 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py:129: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "    if LooseVersion(cmake_version) < '3.1.0':\n",
      "  Building extension for Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "  Invoking CMake setup: 'cmake C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\lib.win-amd64-cpython-39 -DPYTHON_EXECUTABLE=C:\\Users\\USER\\anaconda3\\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\lib.win-amd64-cpython-39 -A x64'\n",
      "  -- Building for: Visual Studio 16 2019\n",
      "  -- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.22621.\n",
      "  -- The C compiler identification is MSVC 19.29.30147.0\n",
      "  -- The CXX compiler identification is MSVC 19.29.30147.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- pybind11 v2.10.0\n",
      "  -- Found PythonInterp: C:/Users/USER/anaconda3/python.exe (found suitable version \"3.9.13\", minimum required is \"3.6\")\n",
      "  -- Found PythonLibs: C:/Users/USER/anaconda3/libs/python39.lib\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG - Success\n",
      "  -- Using CMake version: 3.26.3\n",
      "  -- Compiling dlib version: 19.24.1\n",
      "  -- Looking for sys/types.h\n",
      "  -- Looking for sys/types.h - found\n",
      "  -- Looking for stdint.h\n",
      "  -- Looking for stdint.h - found\n",
      "  -- Looking for stddef.h\n",
      "  -- Looking for stddef.h - found\n",
      "  -- Check size of void*\n",
      "  -- Check size of void* - done\n",
      "  -- Enabling SSE2 instructions\n",
      "  -- Could NOT find WebP (missing: WEBP_LIBRARY)\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "  -- Looking for pthread_create in pthreads\n",
      "  -- Looking for pthread_create in pthreads - not found\n",
      "  -- Looking for pthread_create in pthread\n",
      "  -- Looking for pthread_create in pthread - not found\n",
      "  -- Found Threads: TRUE\n",
      "  CUDA_TOOLKIT_ROOT_DIR not found or specified\n",
      "  -- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) (Required is at least version \"7.5\")\n",
      "  -- Found CUDA, but CMake was unable to find the cuBLAS libraries that should be part of every basic CUDA install. Your CUDA install is somehow broken or incomplete. Since cuBLAS is required for dlib to use CUDA we won't use CUDA.\n",
      "  -- DID NOT FIND CUDA\n",
      "  -- Disabling CUDA support for dlib.  DLIB WILL NOT USE CUDA\n",
      "  -- Searching for FFMPEG/LIBAV\n",
      "  -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\n",
      "  -- PkgConfig could not be found, FFMPEG won't be available\n",
      "  -- Configuring done (65.5s)\n",
      "  -- Generating done (0.3s)\n",
      "  -- Build files have been written to: C:/Users/USER/AppData/Local/Temp/pip-install-a7viuhpt/dlib_9a68ee70b2ad46ca95a1909c1ad71844/build/temp.win-amd64-cpython-39/Release\n",
      "  Invoking CMake build: 'cmake --build . --config Release -- /m'\n",
      "  .NET Framework용 Microsoft (R) Build Engine 버전 16.11.2+f32259642\n",
      "  Copyright (C) Microsoft Corporation. All rights reserved.\n",
      "  \n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\ZERO_CHECK.vcxproj]\n",
      "    Checking Build System\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-a7viuhpt/dlib_9a68ee70b2ad46ca95a1909c1ad71844/dlib/CMakeLists.txt\n",
      "    base64_kernel_1.cpp\n",
      "    bigint_kernel_1.cpp\n",
      "    bigint_kernel_2.cpp\n",
      "    bit_stream_kernel_1.cpp\n",
      "    entropy_decoder_kernel_1.cpp\n",
      "    entropy_decoder_kernel_2.cpp\n",
      "    entropy_encoder_kernel_1.cpp\n",
      "    entropy_encoder_kernel_2.cpp\n",
      "    md5_kernel_1.cpp\n",
      "    tokenizer_kernel_1.cpp\n",
      "    unicode.cpp\n",
      "    test_for_odr_violations.cpp\n",
      "    sockets_kernel_1.cpp\n",
      "    bsp.cpp\n",
      "    dir_nav_kernel_1.cpp\n",
      "    dir_nav_kernel_2.cpp\n",
      "    dir_nav_extensions.cpp\n",
      "    fonts.cpp\n",
      "    linker_kernel_1.cpp\n",
      "    extra_logger_headers.cpp\n",
      "    logger_kernel_1.cpp\n",
      "    logger_config_file.cpp\n",
      "    misc_api_kernel_1.cpp\n",
      "    misc_api_kernel_2.cpp\n",
      "    sockets_extensions.cpp\n",
      "    sockets_kernel_2.cpp\n",
      "    sockstreambuf.cpp\n",
      "    sockstreambuf_unbuffered.cpp\n",
      "    server_kernel.cpp\n",
      "    server_iostream.cpp\n",
      "    server_http.cpp\n",
      "    multithreaded_object_extension.cpp\n",
      "    threaded_object_extension.cpp\n",
      "    threads_kernel_1.cpp\n",
      "    threads_kernel_2.cpp\n",
      "    threads_kernel_shared.cpp\n",
      "    thread_pool_extension.cpp\n",
      "    async.cpp\n",
      "    timer.cpp\n",
      "    stack_trace.cpp\n",
      "    cpu_dlib.cpp\n",
      "    tensor_tools.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    mnist.cpp\n",
      "    cifar.cpp\n",
      "    global_function_search.cpp\n",
      "    kalman_filter.cpp\n",
      "    auto.cpp\n",
      "    widgets.cpp\n",
      "    drawable.cpp\n",
      "    canvas_drawing.cpp\n",
      "    style.cpp\n",
      "    base_widgets.cpp\n",
      "    gui_core_kernel_1.cpp\n",
      "    gui_core_kernel_2.cpp\n",
      "    png_loader.cpp\n",
      "    save_png.cpp\n",
      "    jpeg_loader.cpp\n",
      "    save_jpeg.cpp\n",
      "    arm_init.c\n",
      "    filter_neon_intrinsics.c\n",
      "    palette_neon_intrinsics.c\n",
      "    png.c\n",
      "    pngerror.c\n",
      "    pngget.c\n",
      "    pngmem.c\n",
      "    pngpread.c\n",
      "    pngread.c\n",
      "    pngrio.c\n",
      "    pngrtran.c\n",
      "    pngrutil.c\n",
      "    pngset.c\n",
      "    pngtrans.c\n",
      "    pngwio.c\n",
      "    pngwrite.c\n",
      "    pngwtran.c\n",
      "    pngwutil.c\n",
      "    adler32.c\n",
      "    compress.c\n",
      "    crc32.c\n",
      "    deflate.c\n",
      "    gzclose.c\n",
      "    gzlib.c\n",
      "    gzread.c\n",
      "    gzwrite.c\n",
      "    infback.c\n",
      "    inffast.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzread.c(319,20): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzread.c(400,35): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inflate.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzread.c(472,33): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzwrite.c(212,27): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzwrite.c(232,24): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzwrite.c(371,36): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inftrees.c\n",
      "    trees.c\n",
      "    uncompr.c\n",
      "    zutil.c\n",
      "    jaricom.c\n",
      "    jcapimin.c\n",
      "    jcapistd.c\n",
      "    jcarith.c\n",
      "    jccoefct.c\n",
      "    jccolor.c\n",
      "    jcdctmgr.c\n",
      "    jchuff.c\n",
      "    jcinit.c\n",
      "    jcmainct.c\n",
      "    jcmarker.c\n",
      "    jcmaster.c\n",
      "    jcomapi.c\n",
      "    jcparam.c\n",
      "    jcprepct.c\n",
      "    jcsample.c\n",
      "    jdapimin.c\n",
      "    jdapistd.c\n",
      "    jdarith.c\n",
      "    jdatadst.c\n",
      "    jdatasrc.c\n",
      "    jdcoefct.c\n",
      "    jdcolor.c\n",
      "    jddctmgr.c\n",
      "    jdhuff.c\n",
      "    jdinput.c\n",
      "    jdmainct.c\n",
      "    jdmarker.c\n",
      "    jdmaster.c\n",
      "    jdmerge.c\n",
      "    jdpostct.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jdmarker.c(331,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jdsample.c\n",
      "    jerror.c\n",
      "    jfdctflt.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jdmarker.c(654,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jfdctfst.c\n",
      "    jfdctint.c\n",
      "    jidctflt.c\n",
      "    jidctfst.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jerror.c(194,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jerror.c(196,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jidctint.c\n",
      "    jmemmgr.c\n",
      "    jmemnobs.c\n",
      "    jquant1.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jmemmgr.c(1103,19): warning C4996: 'getenv': This function or variable may be unsafe. Consider using _dupenv_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jmemmgr.c(1106,11): warning C4996: 'sscanf': This function or variable may be unsafe. Consider using sscanf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jquant2.c\n",
      "    jutils.c\n",
      "    dlib.vcxproj -> C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\Release\\dlib19.24.1_release_64bit_msvc1929.lib\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-a7viuhpt/dlib_9a68ee70b2ad46ca95a1909c1ad71844/tools/python/CMakeLists.txt\n",
      "    dlib.cpp\n",
      "    matrix.cpp\n",
      "    vector.cpp\n",
      "    svm_c_trainer.cpp\n",
      "    svm_rank_trainer.cpp\n",
      "    decision_functions.cpp\n",
      "    other.cpp\n",
      "    basic.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\decision_functions.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\svm_c_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\other.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\svm_rank_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\matrix.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\basic.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\dlib.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\vector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    cca.cpp\n",
      "    sequence_segmenter.cpp\n",
      "    svm_struct.cpp\n",
      "    image.cpp\n",
      "    image2.cpp\n",
      "    image3.cpp\n",
      "    image4.cpp\n",
      "    rectangles.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\sequence_segmenter.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\cca.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    object_detection.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\svm_struct.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image2.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image3.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image4.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\rectangles.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    shape_predictor.cpp\n",
      "    correlation_tracker.cpp\n",
      "    face_recognition.cpp\n",
      "    cnn_face_detector.cpp\n",
      "    global_optimization.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    numpy_returns.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\object_detection.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\shape_predictor.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\correlation_tracker.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\face_recognition.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\cnn_face_detector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image_dataset_metadata.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\global_optimization.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\numpy_returns.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    line.cpp\n",
      "    gui.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\gui.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\line.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py\", line 222, in <module>\n",
      "      setup(\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wheel\\bdist_wheel.py\", line 299, in run\n",
      "      self.run_command('build')\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\build.py\", line 24, in run\n",
      "      super().run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py\", line 134, in run\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py\", line 174, in build_extension\n",
      "      subprocess.check_call(cmake_build, cwd=build_folder)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\subprocess.py\", line 373, in check_call\n",
      "      raise CalledProcessError(retcode, cmd)\n",
      "  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'Release', '--', '/m']' returned non-zero exit status 1.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for dlib did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [316 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py:129: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "    if LooseVersion(cmake_version) < '3.1.0':\n",
      "  Building extension for Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "  Invoking CMake setup: 'cmake C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\lib.win-amd64-cpython-39 -DPYTHON_EXECUTABLE=C:\\Users\\USER\\anaconda3\\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\lib.win-amd64-cpython-39 -A x64'\n",
      "  -- Building for: Visual Studio 16 2019\n",
      "  -- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.22621.\n",
      "  -- The C compiler identification is MSVC 19.29.30147.0\n",
      "  -- The CXX compiler identification is MSVC 19.29.30147.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- pybind11 v2.10.0\n",
      "  -- Found PythonInterp: C:/Users/USER/anaconda3/python.exe (found suitable version \"3.9.13\", minimum required is \"3.6\")\n",
      "  -- Found PythonLibs: C:/Users/USER/anaconda3/libs/python39.lib\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG - Success\n",
      "  -- Using CMake version: 3.26.3\n",
      "  -- Compiling dlib version: 19.24.1\n",
      "  -- Looking for sys/types.h\n",
      "  -- Looking for sys/types.h - found\n",
      "  -- Looking for stdint.h\n",
      "  -- Looking for stdint.h - found\n",
      "  -- Looking for stddef.h\n",
      "  -- Looking for stddef.h - found\n",
      "  -- Check size of void*\n",
      "  -- Check size of void* - done\n",
      "  -- Enabling SSE2 instructions\n",
      "  -- Could NOT find WebP (missing: WEBP_LIBRARY)\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "  -- Looking for pthread_create in pthreads\n",
      "  -- Looking for pthread_create in pthreads - not found\n",
      "  -- Looking for pthread_create in pthread\n",
      "  -- Looking for pthread_create in pthread - not found\n",
      "  -- Found Threads: TRUE\n",
      "  CUDA_TOOLKIT_ROOT_DIR not found or specified\n",
      "  -- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) (Required is at least version \"7.5\")\n",
      "  -- Found CUDA, but CMake was unable to find the cuBLAS libraries that should be part of every basic CUDA install. Your CUDA install is somehow broken or incomplete. Since cuBLAS is required for dlib to use CUDA we won't use CUDA.\n",
      "  -- DID NOT FIND CUDA\n",
      "  -- Disabling CUDA support for dlib.  DLIB WILL NOT USE CUDA\n",
      "  -- Searching for FFMPEG/LIBAV\n",
      "  -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\n",
      "  -- PkgConfig could not be found, FFMPEG won't be available\n",
      "  -- Configuring done (70.8s)\n",
      "  -- Generating done (0.3s)\n",
      "  -- Build files have been written to: C:/Users/USER/AppData/Local/Temp/pip-install-a7viuhpt/dlib_9a68ee70b2ad46ca95a1909c1ad71844/build/temp.win-amd64-cpython-39/Release\n",
      "  Invoking CMake build: 'cmake --build . --config Release -- /m'\n",
      "  .NET Framework용 Microsoft (R) Build Engine 버전 16.11.2+f32259642\n",
      "  Copyright (C) Microsoft Corporation. All rights reserved.\n",
      "  \n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\ZERO_CHECK.vcxproj]\n",
      "    Checking Build System\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-a7viuhpt/dlib_9a68ee70b2ad46ca95a1909c1ad71844/dlib/CMakeLists.txt\n",
      "    base64_kernel_1.cpp\n",
      "    bigint_kernel_1.cpp\n",
      "    bigint_kernel_2.cpp\n",
      "    bit_stream_kernel_1.cpp\n",
      "    entropy_decoder_kernel_1.cpp\n",
      "    entropy_decoder_kernel_2.cpp\n",
      "    entropy_encoder_kernel_1.cpp\n",
      "    entropy_encoder_kernel_2.cpp\n",
      "    md5_kernel_1.cpp\n",
      "    tokenizer_kernel_1.cpp\n",
      "    unicode.cpp\n",
      "    test_for_odr_violations.cpp\n",
      "    sockets_kernel_1.cpp\n",
      "    bsp.cpp\n",
      "    dir_nav_kernel_1.cpp\n",
      "    dir_nav_kernel_2.cpp\n",
      "    dir_nav_extensions.cpp\n",
      "    fonts.cpp\n",
      "    linker_kernel_1.cpp\n",
      "    extra_logger_headers.cpp\n",
      "    logger_kernel_1.cpp\n",
      "    logger_config_file.cpp\n",
      "    misc_api_kernel_1.cpp\n",
      "    misc_api_kernel_2.cpp\n",
      "    sockets_extensions.cpp\n",
      "    sockets_kernel_2.cpp\n",
      "    sockstreambuf.cpp\n",
      "    sockstreambuf_unbuffered.cpp\n",
      "    server_kernel.cpp\n",
      "    server_iostream.cpp\n",
      "    server_http.cpp\n",
      "    multithreaded_object_extension.cpp\n",
      "    threaded_object_extension.cpp\n",
      "    threads_kernel_1.cpp\n",
      "    threads_kernel_2.cpp\n",
      "    threads_kernel_shared.cpp\n",
      "    thread_pool_extension.cpp\n",
      "    async.cpp\n",
      "    timer.cpp\n",
      "    stack_trace.cpp\n",
      "    cpu_dlib.cpp\n",
      "    tensor_tools.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    mnist.cpp\n",
      "    cifar.cpp\n",
      "    global_function_search.cpp\n",
      "    kalman_filter.cpp\n",
      "    auto.cpp\n",
      "    widgets.cpp\n",
      "    drawable.cpp\n",
      "    canvas_drawing.cpp\n",
      "    style.cpp\n",
      "    base_widgets.cpp\n",
      "    gui_core_kernel_1.cpp\n",
      "    gui_core_kernel_2.cpp\n",
      "    png_loader.cpp\n",
      "    save_png.cpp\n",
      "    jpeg_loader.cpp\n",
      "    save_jpeg.cpp\n",
      "    arm_init.c\n",
      "    filter_neon_intrinsics.c\n",
      "    palette_neon_intrinsics.c\n",
      "    png.c\n",
      "    pngerror.c\n",
      "    pngget.c\n",
      "    pngmem.c\n",
      "    pngpread.c\n",
      "    pngread.c\n",
      "    pngrio.c\n",
      "    pngrtran.c\n",
      "    pngrutil.c\n",
      "    pngset.c\n",
      "    pngtrans.c\n",
      "    pngwio.c\n",
      "    pngwrite.c\n",
      "    pngwtran.c\n",
      "    pngwutil.c\n",
      "    adler32.c\n",
      "    compress.c\n",
      "    crc32.c\n",
      "    deflate.c\n",
      "    gzclose.c\n",
      "    gzlib.c\n",
      "    gzread.c\n",
      "    gzwrite.c\n",
      "    infback.c\n",
      "    inffast.c\n",
      "    inflate.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzread.c(319,20): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzread.c(400,35): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzwrite.c(212,27): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzread.c(472,33): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzwrite.c(232,24): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\zlib\\gzwrite.c(371,36): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inftrees.c\n",
      "    trees.c\n",
      "    uncompr.c\n",
      "    zutil.c\n",
      "    jaricom.c\n",
      "    jcapimin.c\n",
      "    jcapistd.c\n",
      "    jcarith.c\n",
      "    jccoefct.c\n",
      "    jccolor.c\n",
      "    jcdctmgr.c\n",
      "    jchuff.c\n",
      "    jcinit.c\n",
      "    jcmainct.c\n",
      "    jcmarker.c\n",
      "    jcmaster.c\n",
      "    jcomapi.c\n",
      "    jcparam.c\n",
      "    jcprepct.c\n",
      "    jcsample.c\n",
      "    jdapimin.c\n",
      "    jdapistd.c\n",
      "    jdarith.c\n",
      "    jdatadst.c\n",
      "    jdatasrc.c\n",
      "    jdcoefct.c\n",
      "    jdcolor.c\n",
      "    jddctmgr.c\n",
      "    jdhuff.c\n",
      "    jdinput.c\n",
      "    jdmainct.c\n",
      "    jdmarker.c\n",
      "    jdmaster.c\n",
      "    jdmerge.c\n",
      "    jdpostct.c\n",
      "    jdsample.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jdmarker.c(331,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jerror.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jdmarker.c(654,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jfdctflt.c\n",
      "    jfdctfst.c\n",
      "    jfdctint.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jerror.c(194,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jidctflt.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jerror.c(196,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jidctfst.c\n",
      "    jidctint.c\n",
      "    jmemmgr.c\n",
      "    jmemnobs.c\n",
      "    jquant1.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jmemmgr.c(1103,19): warning C4996: 'getenv': This function or variable may be unsafe. Consider using _dupenv_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\dlib\\external\\libjpeg\\jmemmgr.c(1106,11): warning C4996: 'sscanf': This function or variable may be unsafe. Consider using sscanf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jquant2.c\n",
      "    jutils.c\n",
      "    dlib.vcxproj -> C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\Release\\dlib19.24.1_release_64bit_msvc1929.lib\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-a7viuhpt/dlib_9a68ee70b2ad46ca95a1909c1ad71844/tools/python/CMakeLists.txt\n",
      "    dlib.cpp\n",
      "    matrix.cpp\n",
      "    vector.cpp\n",
      "    svm_c_trainer.cpp\n",
      "    svm_rank_trainer.cpp\n",
      "    decision_functions.cpp\n",
      "    other.cpp\n",
      "    basic.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\other.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\matrix.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\vector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\basic.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\decision_functions.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\svm_c_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\dlib.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    cca.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\svm_rank_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    sequence_segmenter.cpp\n",
      "    svm_struct.cpp\n",
      "    image.cpp\n",
      "    image2.cpp\n",
      "    image3.cpp\n",
      "    image4.cpp\n",
      "    rectangles.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\sequence_segmenter.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\cca.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\svm_struct.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    object_detection.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    shape_predictor.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image2.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image3.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    correlation_tracker.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\rectangles.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image4.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    face_recognition.cpp\n",
      "    cnn_face_detector.cpp\n",
      "    global_optimization.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    numpy_returns.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\object_detection.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\shape_predictor.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\correlation_tracker.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\face_recognition.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\cnn_face_detector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    line.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\image_dataset_metadata.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\global_optimization.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    gui.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\numpy_returns.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\line.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\tools\\python\\src\\gui.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py\", line 222, in <module>\n",
      "      setup(\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py\", line 68, in run\n",
      "      return orig.install.run(self)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\command\\install.py\", line 692, in run\n",
      "      self.run_command('build')\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\build.py\", line 24, in run\n",
      "      super().run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py\", line 134, in run\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-a7viuhpt\\dlib_9a68ee70b2ad46ca95a1909c1ad71844\\setup.py\", line 174, in build_extension\n",
      "      subprocess.check_call(cmake_build, cwd=build_folder)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\subprocess.py\", line 373, in check_call\n",
      "      raise CalledProcessError(retcode, cmd)\n",
      "  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'Release', '--', '/m']' returned non-zero exit status 1.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "dlib\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f7a7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "alabaster                     0.7.12\n",
      "anaconda-client               1.11.0\n",
      "anaconda-navigator            2.3.1\n",
      "anaconda-project              0.11.1\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.2\n",
      "astroid                       2.11.7\n",
      "astropy                       5.1\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.5.1\n",
      "bkcharts                      0.2\n",
      "black                         22.6.0\n",
      "bleach                        4.1.0\n",
      "bokeh                         2.4.3\n",
      "boto3                         1.24.28\n",
      "botocore                      1.27.28\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "certifi                       2022.9.14\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.0.0\n",
      "clyent                        1.2.2\n",
      "cmake                         3.26.3\n",
      "colorama                      0.4.5\n",
      "colorcet                      3.0.0\n",
      "comtypes                      1.1.10\n",
      "conda                         22.9.0\n",
      "conda-build                   3.22.0\n",
      "conda-content-trust           0.1.3\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        1.9.0\n",
      "conda-repo-cli                1.0.20\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "constantly                    15.1.0\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  37.0.1\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.32\n",
      "cytoolz                       0.11.0\n",
      "daal4py                       2021.6.0\n",
      "dask                          2022.7.0\n",
      "datashader                    0.14.1\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.4\n",
      "distributed                   2022.7.0\n",
      "docutils                      0.18.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "fastjsonschema                2.16.2\n",
      "filelock                      3.6.0\n",
      "flake8                        4.0.1\n",
      "Flask                         1.1.2\n",
      "fonttools                     4.25.0\n",
      "fsspec                        2022.7.1\n",
      "future                        0.18.2\n",
      "gensim                        4.1.2\n",
      "glob2                         0.7\n",
      "greenlet                      1.1.1\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.15.0\n",
      "hvplot                        0.8.0\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.3\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.19.3\n",
      "imagesize                     1.4.1\n",
      "importlib-metadata            4.11.3\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.5\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.15.2\n",
      "ipython                       7.31.1\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jdcal                         1.4.1\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        2.11.3\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonschema                    4.16.0\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.3.4\n",
      "jupyter-console               6.4.3\n",
      "jupyter_core                  4.11.1\n",
      "jupyter-server                1.18.1\n",
      "jupyterlab                    3.4.4\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-server             2.10.3\n",
      "jupyterlab-widgets            1.0.0\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.4.2\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "llvmlite                      0.38.0\n",
      "locket                        1.0.0\n",
      "lxml                          4.9.1\n",
      "lz4                           3.1.3\n",
      "Markdown                      3.3.4\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.5.2\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.6.1\n",
      "menuinst                      1.4.19\n",
      "mistune                       0.8.4\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.3.0\n",
      "nbclassic                     0.3.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.4.4\n",
      "nbformat                      5.5.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.8.4\n",
      "nltk                          3.7\n",
      "nose                          1.3.7\n",
      "notebook                      6.4.12\n",
      "numba                         0.55.1\n",
      "numexpr                       2.8.3\n",
      "numpy                         1.21.5\n",
      "numpydoc                      1.4.0\n",
      "olefile                       0.46\n",
      "opencv-python                 4.7.0.72\n",
      "openpyxl                      3.0.10\n",
      "packaging                     21.3\n",
      "pandas                        1.4.4\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.13.1\n",
      "param                         1.12.0\n",
      "paramiko                      2.8.1\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.9.0\n",
      "patsy                         0.5.2\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.2.0\n",
      "pip                           22.2.2\n",
      "pkginfo                       1.8.2\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "poyo                          0.5.0\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.20\n",
      "Protego                       0.1.16\n",
      "psutil                        5.9.0\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.8.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pycurl                        7.45.1\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.1.1\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      2.4.0\n",
      "Pygments                      2.11.2\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.14.5\n",
      "pyls-spyder                   0.4.0\n",
      "PyNaCl                        1.5.0\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     22.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.2\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.0.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.3.3\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.0\n",
      "pytz                          2022.1\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.3.0\n",
      "pywin32                       302\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      2.0.2\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.1.10\n",
      "QtAwesome                     1.0.3\n",
      "qtconsole                     5.2.2\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.28.1\n",
      "requests-file                 1.5.1\n",
      "rope                          0.22.0\n",
      "Rtree                         0.9.7\n",
      "ruamel-yaml-conda             0.15.100\n",
      "s3transfer                    0.6.0\n",
      "scikit-image                  0.19.2\n",
      "scikit-learn                  1.0.2\n",
      "scikit-learn-intelex          2021.20221004.171935\n",
      "scipy                         1.9.1\n",
      "Scrapy                        2.6.2\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    63.4.1\n",
      "sip                           4.19.13\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcollections             2.1.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.1\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.2.2\n",
      "spyder-kernels                2.2.1\n",
      "SQLAlchemy                    1.4.39\n",
      "statsmodels                   0.13.2\n",
      "sympy                         1.10.1\n",
      "tables                        3.6.1\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "terminado                     0.13.1\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss                       0.4\n",
      "tldextract                    3.2.0\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "tomlkit                       0.11.1\n",
      "toolz                         0.11.2\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.1.1\n",
      "Twisted                       22.2.0\n",
      "twisted-iocpsupport           1.0.2\n",
      "typing_extensions             4.3.0\n",
      "ujson                         5.4.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.11\n",
      "w3lib                         1.21.0\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.0.3\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.5.2\n",
      "win-inet-pton                 1.1.0\n",
      "win-unicode-console           0.5\n",
      "wincertstore                  0.2\n",
      "wrapt                         1.14.1\n",
      "xarray                        0.20.1\n",
      "xlrd                          2.0.1\n",
      "XlsxWriter                    3.0.3\n",
      "xlwings                       0.27.15\n",
      "yapf                          0.31.0\n",
      "zict                          2.1.0\n",
      "zipp                          3.8.0\n",
      "zope.interface                5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47abbf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"listall\" - maybe you meant \"install\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip listall dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c9c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.24.1.tar.gz (3.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): still running...\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n",
      "Installing collected packages: dlib\n",
      "  Running setup.py install for dlib: started\n",
      "  Running setup.py install for dlib: still running...\n",
      "  Running setup.py install for dlib: still running...\n",
      "  Running setup.py install for dlib: still running...\n",
      "  Running setup.py install for dlib: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [312 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py:129: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "    if LooseVersion(cmake_version) < '3.1.0':\n",
      "  Building extension for Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "  Invoking CMake setup: 'cmake C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\lib.win-amd64-cpython-39 -DPYTHON_EXECUTABLE=C:\\Users\\USER\\anaconda3\\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\lib.win-amd64-cpython-39 -A x64'\n",
      "  -- Building for: Visual Studio 16 2019\n",
      "  -- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.22621.\n",
      "  -- The C compiler identification is MSVC 19.29.30147.0\n",
      "  -- The CXX compiler identification is MSVC 19.29.30147.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- pybind11 v2.10.0\n",
      "  -- Found PythonInterp: C:/Users/USER/anaconda3/python.exe (found suitable version \"3.9.13\", minimum required is \"3.6\")\n",
      "  -- Found PythonLibs: C:/Users/USER/anaconda3/libs/python39.lib\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG - Success\n",
      "  -- Using CMake version: 3.26.3\n",
      "  -- Compiling dlib version: 19.24.1\n",
      "  -- Looking for sys/types.h\n",
      "  -- Looking for sys/types.h - found\n",
      "  -- Looking for stdint.h\n",
      "  -- Looking for stdint.h - found\n",
      "  -- Looking for stddef.h\n",
      "  -- Looking for stddef.h - found\n",
      "  -- Check size of void*\n",
      "  -- Check size of void* - done\n",
      "  -- Enabling SSE2 instructions\n",
      "  -- Could NOT find WebP (missing: WEBP_LIBRARY)\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "  -- Looking for pthread_create in pthreads\n",
      "  -- Looking for pthread_create in pthreads - not found\n",
      "  -- Looking for pthread_create in pthread\n",
      "  -- Looking for pthread_create in pthread - not found\n",
      "  -- Found Threads: TRUE\n",
      "  CUDA_TOOLKIT_ROOT_DIR not found or specified\n",
      "  -- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) (Required is at least version \"7.5\")\n",
      "  -- Found CUDA, but CMake was unable to find the cuBLAS libraries that should be part of every basic CUDA install. Your CUDA install is somehow broken or incomplete. Since cuBLAS is required for dlib to use CUDA we won't use CUDA.\n",
      "  -- DID NOT FIND CUDA\n",
      "  -- Disabling CUDA support for dlib.  DLIB WILL NOT USE CUDA\n",
      "  -- Searching for FFMPEG/LIBAV\n",
      "  -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\n",
      "  -- PkgConfig could not be found, FFMPEG won't be available\n",
      "  -- Configuring done (63.1s)\n",
      "  -- Generating done (0.3s)\n",
      "  -- Build files have been written to: C:/Users/USER/AppData/Local/Temp/pip-install-8d7u7pso/dlib_5a76605ff45047ba989c549382cb89a1/build/temp.win-amd64-cpython-39/Release\n",
      "  Invoking CMake build: 'cmake --build . --config Release -- /m'\n",
      "  .NET Framework용 Microsoft (R) Build Engine 버전 16.11.2+f32259642\n",
      "  Copyright (C) Microsoft Corporation. All rights reserved.\n",
      "  \n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\ZERO_CHECK.vcxproj]\n",
      "    Checking Build System\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-8d7u7pso/dlib_5a76605ff45047ba989c549382cb89a1/dlib/CMakeLists.txt\n",
      "    base64_kernel_1.cpp\n",
      "    bigint_kernel_1.cpp\n",
      "    bigint_kernel_2.cpp\n",
      "    bit_stream_kernel_1.cpp\n",
      "    entropy_decoder_kernel_1.cpp\n",
      "    entropy_decoder_kernel_2.cpp\n",
      "    entropy_encoder_kernel_1.cpp\n",
      "    entropy_encoder_kernel_2.cpp\n",
      "    md5_kernel_1.cpp\n",
      "    tokenizer_kernel_1.cpp\n",
      "    unicode.cpp\n",
      "    test_for_odr_violations.cpp\n",
      "    sockets_kernel_1.cpp\n",
      "    bsp.cpp\n",
      "    dir_nav_kernel_1.cpp\n",
      "    dir_nav_kernel_2.cpp\n",
      "    dir_nav_extensions.cpp\n",
      "    fonts.cpp\n",
      "    linker_kernel_1.cpp\n",
      "    extra_logger_headers.cpp\n",
      "    logger_kernel_1.cpp\n",
      "    logger_config_file.cpp\n",
      "    misc_api_kernel_1.cpp\n",
      "    misc_api_kernel_2.cpp\n",
      "    sockets_extensions.cpp\n",
      "    sockets_kernel_2.cpp\n",
      "    sockstreambuf.cpp\n",
      "    sockstreambuf_unbuffered.cpp\n",
      "    server_kernel.cpp\n",
      "    server_iostream.cpp\n",
      "    server_http.cpp\n",
      "    multithreaded_object_extension.cpp\n",
      "    threaded_object_extension.cpp\n",
      "    threads_kernel_1.cpp\n",
      "    threads_kernel_2.cpp\n",
      "    threads_kernel_shared.cpp\n",
      "    thread_pool_extension.cpp\n",
      "    async.cpp\n",
      "    timer.cpp\n",
      "    stack_trace.cpp\n",
      "    cpu_dlib.cpp\n",
      "    tensor_tools.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    mnist.cpp\n",
      "    cifar.cpp\n",
      "    global_function_search.cpp\n",
      "    kalman_filter.cpp\n",
      "    auto.cpp\n",
      "    widgets.cpp\n",
      "    drawable.cpp\n",
      "    canvas_drawing.cpp\n",
      "    style.cpp\n",
      "    base_widgets.cpp\n",
      "    gui_core_kernel_1.cpp\n",
      "    gui_core_kernel_2.cpp\n",
      "    png_loader.cpp\n",
      "    save_png.cpp\n",
      "    jpeg_loader.cpp\n",
      "    save_jpeg.cpp\n",
      "    arm_init.c\n",
      "    filter_neon_intrinsics.c\n",
      "    palette_neon_intrinsics.c\n",
      "    png.c\n",
      "    pngerror.c\n",
      "    pngget.c\n",
      "    pngmem.c\n",
      "    pngpread.c\n",
      "    pngread.c\n",
      "    pngrio.c\n",
      "    pngrtran.c\n",
      "    pngrutil.c\n",
      "    pngset.c\n",
      "    pngtrans.c\n",
      "    pngwio.c\n",
      "    pngwrite.c\n",
      "    pngwtran.c\n",
      "    pngwutil.c\n",
      "    adler32.c\n",
      "    compress.c\n",
      "    crc32.c\n",
      "    deflate.c\n",
      "    gzclose.c\n",
      "    gzlib.c\n",
      "    gzread.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzread.c(319,20): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    gzwrite.c\n",
      "    infback.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzread.c(400,35): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzread.c(472,33): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inffast.c\n",
      "    inflate.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzwrite.c(212,27): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzwrite.c(232,24): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzwrite.c(371,36): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inftrees.c\n",
      "    trees.c\n",
      "    uncompr.c\n",
      "    zutil.c\n",
      "    jaricom.c\n",
      "    jcapimin.c\n",
      "    jcapistd.c\n",
      "    jcarith.c\n",
      "    jccoefct.c\n",
      "    jccolor.c\n",
      "    jcdctmgr.c\n",
      "    jchuff.c\n",
      "    jcinit.c\n",
      "    jcmainct.c\n",
      "    jcmarker.c\n",
      "    jcmaster.c\n",
      "    jcomapi.c\n",
      "    jcparam.c\n",
      "    jcprepct.c\n",
      "    jcsample.c\n",
      "    jdapimin.c\n",
      "    jdapistd.c\n",
      "    jdarith.c\n",
      "    jdatadst.c\n",
      "    jdatasrc.c\n",
      "    jdcoefct.c\n",
      "    jdcolor.c\n",
      "    jddctmgr.c\n",
      "    jdhuff.c\n",
      "    jdinput.c\n",
      "    jdmainct.c\n",
      "    jdmarker.c\n",
      "    jdmaster.c\n",
      "    jdmerge.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jdmarker.c(331,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jdpostct.c\n",
      "    jdsample.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jdmarker.c(654,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jerror.c\n",
      "    jfdctflt.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jerror.c(194,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jerror.c(196,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jfdctfst.c\n",
      "    jfdctint.c\n",
      "    jidctflt.c\n",
      "    jidctfst.c\n",
      "    jidctint.c\n",
      "    jmemmgr.c\n",
      "    jmemnobs.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jmemmgr.c(1103,19): warning C4996: 'getenv': This function or variable may be unsafe. Consider using _dupenv_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jmemmgr.c(1106,11): warning C4996: 'sscanf': This function or variable may be unsafe. Consider using sscanf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jquant1.c\n",
      "    jquant2.c\n",
      "    jutils.c\n",
      "    dlib.vcxproj -> C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\Release\\dlib19.24.1_release_64bit_msvc1929.lib\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-8d7u7pso/dlib_5a76605ff45047ba989c549382cb89a1/tools/python/CMakeLists.txt\n",
      "    dlib.cpp\n",
      "    matrix.cpp\n",
      "    vector.cpp\n",
      "    svm_c_trainer.cpp\n",
      "    svm_rank_trainer.cpp\n",
      "    decision_functions.cpp\n",
      "    other.cpp\n",
      "    basic.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\dlib.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\svm_rank_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\basic.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\matrix.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\decision_functions.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\other.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\vector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    cca.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\svm_c_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    sequence_segmenter.cpp\n",
      "    svm_struct.cpp\n",
      "    image.cpp\n",
      "    image2.cpp\n",
      "    image3.cpp\n",
      "    image4.cpp\n",
      "    rectangles.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\sequence_segmenter.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\cca.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\svm_struct.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    object_detection.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image2.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image3.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image4.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    shape_predictor.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\rectangles.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    correlation_tracker.cpp\n",
      "    face_recognition.cpp\n",
      "    cnn_face_detector.cpp\n",
      "    global_optimization.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    numpy_returns.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\object_detection.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\shape_predictor.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\correlation_tracker.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\face_recognition.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\cnn_face_detector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\numpy_returns.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image_dataset_metadata.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\global_optimization.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    line.cpp\n",
      "    gui.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\line.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\gui.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py\", line 222, in <module>\n",
      "      setup(\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\wheel\\bdist_wheel.py\", line 299, in run\n",
      "      self.run_command('build')\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\build.py\", line 24, in run\n",
      "      super().run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py\", line 134, in run\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py\", line 174, in build_extension\n",
      "      subprocess.check_call(cmake_build, cwd=build_folder)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\subprocess.py\", line 373, in check_call\n",
      "      raise CalledProcessError(retcode, cmd)\n",
      "  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'Release', '--', '/m']' returned non-zero exit status 1.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for dlib did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [316 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py:129: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "    if LooseVersion(cmake_version) < '3.1.0':\n",
      "  Building extension for Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "  Invoking CMake setup: 'cmake C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\lib.win-amd64-cpython-39 -DPYTHON_EXECUTABLE=C:\\Users\\USER\\anaconda3\\python.exe -DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE=C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\lib.win-amd64-cpython-39 -A x64'\n",
      "  -- Building for: Visual Studio 16 2019\n",
      "  -- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.22621.\n",
      "  -- The C compiler identification is MSVC 19.29.30147.0\n",
      "  -- The CXX compiler identification is MSVC 19.29.30147.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30133/bin/Hostx64/x64/cl.exe - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- pybind11 v2.10.0\n",
      "  -- Found PythonInterp: C:/Users/USER/anaconda3/python.exe (found suitable version \"3.9.13\", minimum required is \"3.6\")\n",
      "  -- Found PythonLibs: C:/Users/USER/anaconda3/libs/python39.lib\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG\n",
      "  -- Performing Test HAS_MSVC_GL_LTCG - Success\n",
      "  -- Using CMake version: 3.26.3\n",
      "  -- Compiling dlib version: 19.24.1\n",
      "  -- Looking for sys/types.h\n",
      "  -- Looking for sys/types.h - found\n",
      "  -- Looking for stdint.h\n",
      "  -- Looking for stdint.h - found\n",
      "  -- Looking for stddef.h\n",
      "  -- Looking for stddef.h - found\n",
      "  -- Check size of void*\n",
      "  -- Check size of void* - done\n",
      "  -- Enabling SSE2 instructions\n",
      "  -- Could NOT find WebP (missing: WEBP_LIBRARY)\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Searching for BLAS and LAPACK\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "  -- Looking for pthread_create in pthreads\n",
      "  -- Looking for pthread_create in pthreads - not found\n",
      "  -- Looking for pthread_create in pthread\n",
      "  -- Looking for pthread_create in pthread - not found\n",
      "  -- Found Threads: TRUE\n",
      "  CUDA_TOOLKIT_ROOT_DIR not found or specified\n",
      "  -- Could NOT find CUDA (missing: CUDA_TOOLKIT_ROOT_DIR CUDA_NVCC_EXECUTABLE CUDA_INCLUDE_DIRS CUDA_CUDART_LIBRARY) (Required is at least version \"7.5\")\n",
      "  -- Found CUDA, but CMake was unable to find the cuBLAS libraries that should be part of every basic CUDA install. Your CUDA install is somehow broken or incomplete. Since cuBLAS is required for dlib to use CUDA we won't use CUDA.\n",
      "  -- DID NOT FIND CUDA\n",
      "  -- Disabling CUDA support for dlib.  DLIB WILL NOT USE CUDA\n",
      "  -- Searching for FFMPEG/LIBAV\n",
      "  -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE)\n",
      "  -- PkgConfig could not be found, FFMPEG won't be available\n",
      "  -- Configuring done (57.1s)\n",
      "  -- Generating done (0.2s)\n",
      "  -- Build files have been written to: C:/Users/USER/AppData/Local/Temp/pip-install-8d7u7pso/dlib_5a76605ff45047ba989c549382cb89a1/build/temp.win-amd64-cpython-39/Release\n",
      "  Invoking CMake build: 'cmake --build . --config Release -- /m'\n",
      "  .NET Framework용 Microsoft (R) Build Engine 버전 16.11.2+f32259642\n",
      "  Copyright (C) Microsoft Corporation. All rights reserved.\n",
      "  \n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\ZERO_CHECK.vcxproj]\n",
      "    Checking Build System\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-8d7u7pso/dlib_5a76605ff45047ba989c549382cb89a1/dlib/CMakeLists.txt\n",
      "    base64_kernel_1.cpp\n",
      "    bigint_kernel_1.cpp\n",
      "    bigint_kernel_2.cpp\n",
      "    bit_stream_kernel_1.cpp\n",
      "    entropy_decoder_kernel_1.cpp\n",
      "    entropy_decoder_kernel_2.cpp\n",
      "    entropy_encoder_kernel_1.cpp\n",
      "    entropy_encoder_kernel_2.cpp\n",
      "    md5_kernel_1.cpp\n",
      "    tokenizer_kernel_1.cpp\n",
      "    unicode.cpp\n",
      "    test_for_odr_violations.cpp\n",
      "    sockets_kernel_1.cpp\n",
      "    bsp.cpp\n",
      "    dir_nav_kernel_1.cpp\n",
      "    dir_nav_kernel_2.cpp\n",
      "    dir_nav_extensions.cpp\n",
      "    fonts.cpp\n",
      "    linker_kernel_1.cpp\n",
      "    extra_logger_headers.cpp\n",
      "    logger_kernel_1.cpp\n",
      "    logger_config_file.cpp\n",
      "    misc_api_kernel_1.cpp\n",
      "    misc_api_kernel_2.cpp\n",
      "    sockets_extensions.cpp\n",
      "    sockets_kernel_2.cpp\n",
      "    sockstreambuf.cpp\n",
      "    sockstreambuf_unbuffered.cpp\n",
      "    server_kernel.cpp\n",
      "    server_iostream.cpp\n",
      "    server_http.cpp\n",
      "    multithreaded_object_extension.cpp\n",
      "    threaded_object_extension.cpp\n",
      "    threads_kernel_1.cpp\n",
      "    threads_kernel_2.cpp\n",
      "    threads_kernel_shared.cpp\n",
      "    thread_pool_extension.cpp\n",
      "    async.cpp\n",
      "    timer.cpp\n",
      "    stack_trace.cpp\n",
      "    cpu_dlib.cpp\n",
      "    tensor_tools.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    mnist.cpp\n",
      "    cifar.cpp\n",
      "    global_function_search.cpp\n",
      "    kalman_filter.cpp\n",
      "    auto.cpp\n",
      "    widgets.cpp\n",
      "    drawable.cpp\n",
      "    canvas_drawing.cpp\n",
      "    style.cpp\n",
      "    base_widgets.cpp\n",
      "    gui_core_kernel_1.cpp\n",
      "    gui_core_kernel_2.cpp\n",
      "    png_loader.cpp\n",
      "    save_png.cpp\n",
      "    jpeg_loader.cpp\n",
      "    save_jpeg.cpp\n",
      "    arm_init.c\n",
      "    filter_neon_intrinsics.c\n",
      "    palette_neon_intrinsics.c\n",
      "    png.c\n",
      "    pngerror.c\n",
      "    pngget.c\n",
      "    pngmem.c\n",
      "    pngpread.c\n",
      "    pngread.c\n",
      "    pngrio.c\n",
      "    pngrtran.c\n",
      "    pngrutil.c\n",
      "    pngset.c\n",
      "    pngtrans.c\n",
      "    pngwio.c\n",
      "    pngwrite.c\n",
      "    pngwtran.c\n",
      "    pngwutil.c\n",
      "    adler32.c\n",
      "    compress.c\n",
      "    crc32.c\n",
      "    deflate.c\n",
      "    gzclose.c\n",
      "    gzlib.c\n",
      "    gzread.c\n",
      "    gzwrite.c\n",
      "    infback.c\n",
      "    inffast.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzread.c(319,20): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzread.c(400,35): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzwrite.c(212,27): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzread.c(472,33): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inflate.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzwrite.c(232,24): warning C4267: '=': 'size_t'에서 'unsigned int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\zlib\\gzwrite.c(371,36): warning C4267: '=': 'size_t'에서 'int'(으)로 변환하면서 데이터가 손실될 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    inftrees.c\n",
      "    trees.c\n",
      "    uncompr.c\n",
      "    zutil.c\n",
      "    jaricom.c\n",
      "    jcapimin.c\n",
      "    jcapistd.c\n",
      "    jcarith.c\n",
      "    jccoefct.c\n",
      "    jccolor.c\n",
      "    jcdctmgr.c\n",
      "    jchuff.c\n",
      "    jcinit.c\n",
      "    jcmainct.c\n",
      "    jcmarker.c\n",
      "    jcmaster.c\n",
      "    jcomapi.c\n",
      "    jcparam.c\n",
      "    jcprepct.c\n",
      "    jcsample.c\n",
      "    jdapimin.c\n",
      "    jdapistd.c\n",
      "    jdarith.c\n",
      "    jdatadst.c\n",
      "    jdatasrc.c\n",
      "    jdcoefct.c\n",
      "    jdcolor.c\n",
      "    jddctmgr.c\n",
      "    jdhuff.c\n",
      "    jdinput.c\n",
      "    jdmainct.c\n",
      "    jdmarker.c\n",
      "    jdmaster.c\n",
      "    jdmerge.c\n",
      "    jdpostct.c\n",
      "    jdsample.c\n",
      "    jerror.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jdmarker.c(331,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jdmarker.c(654,5): warning C4996: 'strncpy': This function or variable may be unsafe. Consider using strncpy_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jerror.c(194,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jfdctflt.c\n",
      "    jfdctfst.c\n",
      "    jfdctint.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jerror.c(196,5): warning C4996: 'sprintf': This function or variable may be unsafe. Consider using sprintf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jidctflt.c\n",
      "    jidctfst.c\n",
      "    jidctint.c\n",
      "    jmemmgr.c\n",
      "    jmemnobs.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jmemmgr.c(1103,19): warning C4996: 'getenv': This function or variable may be unsafe. Consider using _dupenv_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    jquant1.c\n",
      "    jquant2.c\n",
      "    jutils.c\n",
      "  C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\dlib\\external\\libjpeg\\jmemmgr.c(1106,11): warning C4996: 'sscanf': This function or variable may be unsafe. Consider using sscanf_s instead. To disable deprecation, use _CRT_SECURE_NO_WARNINGS. See online help for details. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\dlib.vcxproj]\n",
      "    dlib.vcxproj -> C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\dlib_build\\Release\\dlib19.24.1_release_64bit_msvc1929.lib\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\MSBuild\\Microsoft\\VC\\v160\\Microsoft.CppBuild.targets(517,5): warning MSB8029: 중간 디렉터리 또는 출력 디렉터리는 임시 디렉터리 아래에 있을 수 없습니다. 임시 디렉터리 아래에 있으면 증분 빌드 시 문제가 발생할 수 있습니다. [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    Building Custom Rule C:/Users/USER/AppData/Local/Temp/pip-install-8d7u7pso/dlib_5a76605ff45047ba989c549382cb89a1/tools/python/CMakeLists.txt\n",
      "    dlib.cpp\n",
      "    matrix.cpp\n",
      "    vector.cpp\n",
      "    svm_c_trainer.cpp\n",
      "    svm_rank_trainer.cpp\n",
      "    decision_functions.cpp\n",
      "    other.cpp\n",
      "    basic.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\svm_rank_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\dlib.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\svm_c_trainer.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\other.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\matrix.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\decision_functions.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\vector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\basic.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    cca.cpp\n",
      "    sequence_segmenter.cpp\n",
      "    svm_struct.cpp\n",
      "    image.cpp\n",
      "    image2.cpp\n",
      "    image3.cpp\n",
      "    image4.cpp\n",
      "    rectangles.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\cca.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    object_detection.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\svm_struct.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\sequence_segmenter.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image2.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image4.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image3.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\rectangles.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    shape_predictor.cpp\n",
      "    correlation_tracker.cpp\n",
      "    face_recognition.cpp\n",
      "    cnn_face_detector.cpp\n",
      "    global_optimization.cpp\n",
      "    image_dataset_metadata.cpp\n",
      "    numpy_returns.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\object_detection.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\shape_predictor.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\face_recognition.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\correlation_tracker.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\cnn_face_detector.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\global_optimization.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\image_dataset_metadata.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "    line.cpp\n",
      "    gui.cpp\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\numpy_returns.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\line.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  C:\\Users\\USER\\anaconda3\\Library\\include\\gif_lib.h(286,61): error C2734: 'GifAsciiTable8x8': const 개체는 extern이 아닌 경우 초기화될 수 있습니다. (소스 파일 컴파일 중 C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\tools\\python\\src\\gui.cpp) [C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\build\\temp.win-amd64-cpython-39\\Release\\_dlib_pybind11.vcxproj]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py\", line 222, in <module>\n",
      "      setup(\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\__init__.py\", line 87, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "      return run_commands(dist)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py\", line 68, in run\n",
      "      return orig.install.run(self)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\command\\install.py\", line 692, in run\n",
      "      self.run_command('build')\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\command\\build.py\", line 24, in run\n",
      "      super().run()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 132, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 319, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\dist.py\", line 1217, in run_command\n",
      "      super().run_command(command)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 992, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py\", line 134, in run\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-8d7u7pso\\dlib_5a76605ff45047ba989c549382cb89a1\\setup.py\", line 174, in build_extension\n",
      "      subprocess.check_call(cmake_build, cwd=build_folder)\n",
      "    File \"C:\\Users\\USER\\anaconda3\\lib\\subprocess.py\", line 373, in check_call\n",
      "      raise CalledProcessError(retcode, cmd)\n",
      "  subprocess.CalledProcessError: Command '['cmake', '--build', '.', '--config', 'Release', '--', '/m']' returned non-zero exit status 1.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "dlib\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ef8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7548e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "absl-py                 1.3.0\n",
      "aiohttp                 3.8.3\n",
      "aiosignal               1.2.0\n",
      "anyio                   3.5.0\n",
      "argon2-cffi             21.3.0\n",
      "argon2-cffi-bindings    21.2.0\n",
      "astunparse              1.6.3\n",
      "async-timeout           4.0.2\n",
      "asynctest               0.13.0\n",
      "attrs                   22.1.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.11.1\n",
      "bleach                  4.1.0\n",
      "blinker                 1.4\n",
      "brotlipy                0.7.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2022.12.7\n",
      "cffi                    1.15.1\n",
      "charset-normalizer      2.0.4\n",
      "click                   8.0.4\n",
      "cmake                   3.26.3\n",
      "colorama                0.4.6\n",
      "cryptography            39.0.1\n",
      "cycler                  0.11.0\n",
      "debugpy                 1.5.1\n",
      "decorator               5.1.1\n",
      "defusedxml              0.7.1\n",
      "dlib                    19.24.1\n",
      "entrypoints             0.4\n",
      "fastjsonschema          2.16.2\n",
      "flatbuffers             2.0\n",
      "flit_core               3.6.0\n",
      "fonttools               4.38.0\n",
      "frozenlist              1.3.3\n",
      "gast                    0.4.0\n",
      "google-auth             2.6.0\n",
      "google-auth-oauthlib    0.4.4\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.42.0\n",
      "gTTS                    2.3.1\n",
      "h5py                    3.7.0\n",
      "idna                    3.4\n",
      "importlib-metadata      4.11.3\n",
      "importlib-resources     5.2.0\n",
      "imutils                 0.5.4\n",
      "ipykernel               6.15.2\n",
      "ipython                 7.31.1\n",
      "ipython-genutils        0.2.0\n",
      "jedi                    0.18.1\n",
      "Jinja2                  3.1.2\n",
      "joblib                  1.1.1\n",
      "jsonschema              4.17.3\n",
      "jupyter_client          7.4.9\n",
      "jupyter_core            4.11.2\n",
      "jupyter-server          1.23.4\n",
      "jupyterlab-pygments     0.1.2\n",
      "keras                   2.10.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.4.4\n",
      "Markdown                3.4.1\n",
      "MarkupSafe              2.1.1\n",
      "matplotlib              3.5.3\n",
      "matplotlib-inline       0.1.6\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.3.1\n",
      "mkl-random              1.2.2\n",
      "mkl-service             2.4.0\n",
      "multidict               6.0.2\n",
      "nbclassic               0.5.2\n",
      "nbclient                0.5.13\n",
      "nbconvert               6.4.4\n",
      "nbformat                5.7.0\n",
      "nest-asyncio            1.5.6\n",
      "notebook                6.5.2\n",
      "notebook_shim           0.2.2\n",
      "numpy                   1.21.5\n",
      "oauthlib                3.2.1\n",
      "opencv-python           4.7.0.72\n",
      "opt-einsum              3.3.0\n",
      "packaging               22.0\n",
      "pandas                  1.3.5\n",
      "pandocfilters           1.5.0\n",
      "parso                   0.8.3\n",
      "pickleshare             0.7.5\n",
      "Pillow                  9.5.0\n",
      "pip                     22.3.1\n",
      "pkgutil_resolve_name    1.3.10\n",
      "prometheus-client       0.14.1\n",
      "prompt-toolkit          3.0.36\n",
      "protobuf                3.20.3\n",
      "psutil                  5.9.0\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.21\n",
      "Pygments                2.11.2\n",
      "PyJWT                   2.4.0\n",
      "pyOpenSSL               23.0.0\n",
      "pyparsing               3.0.9\n",
      "pyrsistent              0.18.0\n",
      "PySocks                 1.7.1\n",
      "python-dateutil         2.8.2\n",
      "pytz                    2023.3\n",
      "pywin32                 305.1\n",
      "pywinpty                2.0.10\n",
      "pyzmq                   23.2.0\n",
      "requests                2.28.1\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "scikit-learn            1.0.2\n",
      "scipy                   1.7.3\n",
      "seaborn                 0.12.2\n",
      "Send2Trash              1.8.0\n",
      "setuptools              65.6.3\n",
      "six                     1.16.0\n",
      "sniffio                 1.2.0\n",
      "soupsieve               2.3.2.post1\n",
      "tensorboard             2.10.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.1\n",
      "tensorflow              2.10.0\n",
      "tensorflow-estimator    2.10.0\n",
      "termcolor               2.1.0\n",
      "terminado               0.17.1\n",
      "testpath                0.6.0\n",
      "threadpoolctl           2.2.0\n",
      "tornado                 6.2\n",
      "traitlets               5.7.1\n",
      "typing_extensions       4.4.0\n",
      "urllib3                 1.26.14\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        0.58.0\n",
      "Werkzeug                2.2.2\n",
      "wheel                   0.38.4\n",
      "win-inet-pton           1.1.0\n",
      "wincertstore            0.2\n",
      "wrapt                   1.14.1\n",
      "yarl                    1.8.1\n",
      "zipp                    3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d92d7bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open Downloads/shape_predictor_68_face_landmarks(1).dat.bz2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\3116047742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/shape_predictor_68_face_landmarks(1).dat.bz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open Downloads/shape_predictor_68_face_landmarks(1).dat.bz2"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks(1).dat.bz2')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7519f170",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open Downloads/shape_predictor_68_face_landmarks  (1).dat.bz2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\1873248227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/shape_predictor_68_face_landmarks  (1).dat.bz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open Downloads/shape_predictor_68_face_landmarks  (1).dat.bz2"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks  (1).dat.bz2')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e0896b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open Downloads/shape_predictor_68_face_landmarks%20(1).dat.bz2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\507270884.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/shape_predictor_68_face_landmarks%20(1).dat.bz2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open Downloads/shape_predictor_68_face_landmarks%20(1).dat.bz2"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks%20(1).dat.bz2')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e1700f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open Downloads/shape_predictor_68_face_landmarks%20(1).dat/shape_predictor_68_face_landmarks%20(1).dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\1723395295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/shape_predictor_68_face_landmarks%20(1).dat/shape_predictor_68_face_landmarks%20(1).dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open Downloads/shape_predictor_68_face_landmarks%20(1).dat/shape_predictor_68_face_landmarks%20(1).dat"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks%20(1).dat/shape_predictor_68_face_landmarks%20(1).dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ade4685",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open Downloads/shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\3982161038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open Downloads/shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Downloads/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc17d7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (393759803.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11096\\393759803.py\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\shape_predictor_68_face_landmarks (1).dat\\shape_predictor_68_face_landmarks (1).dat')\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\shape_predictor_68_face_landmarks (1).dat\\shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae1ea09",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at models/2018_12_17_22_58_35.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\2725362310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         raise IOError(\n\u001b[1;32m--> 227\u001b[1;33m                             \u001b[1;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m                         )\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at models/2018_12_17_22_58_35.h5"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('models/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87d493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0150083b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5707d1b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1426620254.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2356\\1426620254.py\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    predictor = dlib.shape_predictor('C:\\Users\\USER\\Desktop\\blink_image.png')\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:\\Users\\USER\\Desktop\\blink_image.png')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27042234",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2141055652.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2356\\2141055652.py\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\blink_imag.data')\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\blink_imag.data')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292765a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3318506821.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2356\\3318506821.py\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1\\blink.dat')\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1\\blink.dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3070d5d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3318506821.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2356\\3318506821.py\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    predictor = dlib.shape_predictor('C:\\Users\\USER\\Downloads\\media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1\\blink.dat')\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1/blink.dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8133633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error deserializing object of type int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2356\\2949082547.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/USER/Downloads/media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1/blink.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error deserializing object of type int"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1/blink.dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    \n",
    "    movie_file='C:/Users/USER/Downloads/blink_mp4.mp4'\n",
    "\n",
    "    vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "    if vfile.isOpened():\n",
    "        while True:\n",
    "            vret, img = vfile.read()\n",
    "            if vret:\n",
    "                cv2.imshow(movie_file, img)\n",
    "                cv2.waitKey(25)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"파일을 열 수 없습니다.\")\n",
    "\n",
    "    vfile.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5658acb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2410357720.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2356\\2410357720.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    movie_file='C:\\Users\\USER\\Downloads\\blink_mp4.mp4'\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "movie_file='C:/Users/USER/Downloads/blink_mp4.mp4'\n",
    "\n",
    "vfile = cb2.VideoCapture(movie_file)\n",
    "\n",
    "if vfile.isOpened():\n",
    "    while True:\n",
    "        vret, img = vfile.read()\n",
    "        if vret:\n",
    "            cv2.imshow(movie_file, img)\n",
    "            cv2.waitKey(25)\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print(\"파일을 열 수 없습니다.\")\n",
    "    \n",
    "vfile.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c887450a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cb2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2356\\4172811118.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmovie_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:/Users/USER/Downloads/blink_mp4.mp4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cb2' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "movie_file='C:/Users/USER/Downloads/blink_mp4.mp4'\n",
    "\n",
    "vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "if vfile.isOpened():\n",
    "    while True:\n",
    "        vret, img = vfile.read()\n",
    "        if vret:\n",
    "            cv2.imshow(movie_file, img)\n",
    "            cv2.waitKey(25)\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print(\"파일을 열 수 없습니다.\")\n",
    "    \n",
    "vfile.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780fa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "movie_file='C:/Users/USER/Downloads/blink_mp4.mp4'\n",
    "\n",
    "vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "if vfile.isOpened():\n",
    "    while True:\n",
    "        vret, img = vfile.read()\n",
    "        if vret:\n",
    "            cv2.imshow(movie_file, img)\n",
    "            cv2.waitKey(25)\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    print(\"파일을 열 수 없습니다.\")\n",
    "    \n",
    "vfile.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964a658a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error deserializing object of type int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2356\\62839759.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/USER/Downloads/media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1/blink.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error deserializing object of type int"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/media.io_ksr3ddPi-ae753532edbfef03bb971a23f2a583c1/blink.dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    \n",
    "    movie_file='C:/Users/USER/Downloads/blink_mp4.mp4'\n",
    "\n",
    "    vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "    if vfile.isOpened():\n",
    "        while True:\n",
    "            vret, img = vfile.read()\n",
    "            if vret:\n",
    "                cv2.imshow(movie_file, img)\n",
    "                cv2.waitKey(25)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"파일을 열 수 없습니다.\")\n",
    "\n",
    "    vfile.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6eccfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    \n",
    "    movie_file='C:/Users/USER/Downloads/blink_mp4.mp4'\n",
    "\n",
    "    vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "    if vfile.isOpened():\n",
    "        while True:\n",
    "            vret, img = vfile.read()\n",
    "            if vret:\n",
    "                cv2.imshow(movie_file, img)\n",
    "                cv2.waitKey(25)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"파일을 열 수 없습니다.\")\n",
    "\n",
    "    vfile.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47d045f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    \n",
    "    movie_file= predictor\n",
    "    \n",
    "    vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "    if vfile.isOpened():\n",
    "        while True:\n",
    "            vret, img = vfile.read()\n",
    "            if vret:\n",
    "                cv2.imshow(movie_file, img)\n",
    "                cv2.waitKey(25)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"파일을 열 수 없습니다.\")\n",
    "\n",
    "    vfile.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e81fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    \n",
    "    movie_file= predictor\n",
    "    \n",
    "    vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "    if vfile.isOpened():\n",
    "        while True:\n",
    "            vret, img = vfile.read()\n",
    "            if vret:\n",
    "                cv2.imshow(movie_file, img)\n",
    "                cv2.waitKey(25)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"파일을 열 수 없습니다.\")\n",
    "\n",
    "    vfile.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a330e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    \n",
    "    movie_file= predictor\n",
    "    \n",
    "    vfile = cv2.VideoCapture(movie_file)\n",
    "\n",
    "    if vfile.isOpened():\n",
    "        while True:\n",
    "            vret, img = vfile.read()\n",
    "            if vret:\n",
    "                cv2.imshow(movie_file, img)\n",
    "                cv2.waitKey(25)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        print(\"파일을 열 수 없습니다.\")\n",
    "\n",
    "    vfile.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79abbdc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2356\\1208195519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2018_12_17_22_58_35.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "model = load_model('2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('videos/2.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb1aa98",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1040575569.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2356\\1040575569.py\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    cap = cv2.VideoCapture('C:\\Users\\USER\\Downloads\\blink_mp4.mp4')\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:\\Users\\USER\\Downloads\\blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    if state_l <= 0.0 :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,0,0), thickness=2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "     \n",
    "    if state_r <= 0.0 :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,0,0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac84843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 839ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Pictures/Screenshots/스크린샷 2023-05-11 001405.png')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fd6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Pictures/Screenshots/스크린샷 2023-05-11 001405.png')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b72bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Desktop/baby_blink.png')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9c9bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               786944    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "model.summary()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Desktop/baby_blink.png')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a4bc05",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (357142840.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_16280\\357142840.py\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    cap = cv2.VideoCapture('C:\\Users\\USER\\Downloads\\blink_mp4.mp4')\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Downloads/blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    if state_l <= 0.0 :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,0,0), thickness=2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "     \n",
    "    if state_r <= 0.0 :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,0,0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af02efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16280\\2223854717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mstate_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_r\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpred_r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mstate_l\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_rect_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_rect_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Downloads/blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    if state_l <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,0,0), thickness=2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "     \n",
    "    if state_r <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,0,0), thickness=2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7c74fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Downloads/blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    if state_l <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "     \n",
    "    if state_r <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83bffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import time\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Downloads/blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_rstart = time.time()\n",
    "    \n",
    "    start = time.time()\n",
    "    math.factorial(100000)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"{end - start:.5f} sec\")\n",
    "\n",
    "    if state_l <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "     \n",
    "    if state_r <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa867b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 783ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.36304 sec\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "0.44300 sec\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0.41896 sec\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.33647 sec\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0.36272 sec\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.32082 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "0.33858 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.31204 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.36340 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.31718 sec\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.33795 sec\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.31274 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.33436 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "0.32837 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.37391 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "0.32479 sec\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.31062 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "0.32224 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "0.36139 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.33344 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.32328 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.32756 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.31361 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "0.33142 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "0.37494 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "0.34172 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.32533 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "0.31874 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.34254 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.32635 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.36441 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.32803 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.30821 sec\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.33170 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.32811 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.34752 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.32288 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.33731 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.36244 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.32623 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.33662 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "0.31880 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "0.31872 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.32850 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.31909 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.37653 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.32726 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.32428 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.33236 sec\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.32512 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "0.32454 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.35177 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.32812 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.32886 sec\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.33322 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.33532 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.32380 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "0.34080 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.33762 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0.32053 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "0.32588 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "0.30434 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.31468 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.33423 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.30473 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "0.32249 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "0.33611 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.29992 sec\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.33442 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.33854 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.33788 sec\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "0.33381 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "0.31776 sec\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0.38807 sec\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.32944 sec\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "0.33961 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "0.31302 sec\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0.35630 sec\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "0.36856 sec\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0.43405 sec\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.43255 sec\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0.46806 sec\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "0.44542 sec\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "0.51075 sec\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "0.33516 sec\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0.40798 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.37081 sec\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "0.32301 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "0.35135 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.30862 sec\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "0.34582 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "0.35278 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.33283 sec\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.32140 sec\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "0.32636 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.32856 sec\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "0.32632 sec\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "0.30094 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "0.32098 sec\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "0.32853 sec\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.32119 sec\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0.34142 sec\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "0.35197 sec\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import time\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/2018_12_17_22_58_35.h5')\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Downloads/blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    if state_l <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "     \n",
    "    if state_r <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad1057b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15508\\3874658707.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5beadee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "absl-py                 1.3.0\n",
      "aiohttp                 3.8.3\n",
      "aiosignal               1.2.0\n",
      "anyio                   3.5.0\n",
      "argon2-cffi             21.3.0\n",
      "argon2-cffi-bindings    21.2.0\n",
      "astunparse              1.6.3\n",
      "async-timeout           4.0.2\n",
      "asynctest               0.13.0\n",
      "attrs                   22.1.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.11.1\n",
      "bleach                  4.1.0\n",
      "blinker                 1.4\n",
      "brotlipy                0.7.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2022.12.7\n",
      "cffi                    1.15.1\n",
      "charset-normalizer      2.0.4\n",
      "click                   8.0.4\n",
      "cmake                   3.26.3\n",
      "colorama                0.4.6\n",
      "cryptography            39.0.1\n",
      "cycler                  0.11.0\n",
      "debugpy                 1.5.1\n",
      "decorator               5.1.1\n",
      "defusedxml              0.7.1\n",
      "dlib                    19.24.1\n",
      "entrypoints             0.4\n",
      "fastjsonschema          2.16.2\n",
      "flatbuffers             2.0\n",
      "flit_core               3.6.0\n",
      "fonttools               4.38.0\n",
      "frozenlist              1.3.3\n",
      "gast                    0.4.0\n",
      "google-auth             2.6.0\n",
      "google-auth-oauthlib    0.4.4\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.42.0\n",
      "gTTS                    2.3.1\n",
      "h5py                    3.7.0\n",
      "idna                    3.4\n",
      "importlib-metadata      4.11.3\n",
      "importlib-resources     5.2.0\n",
      "imutils                 0.5.4\n",
      "ipykernel               6.15.2\n",
      "ipython                 7.31.1\n",
      "ipython-genutils        0.2.0\n",
      "jedi                    0.18.1\n",
      "Jinja2                  3.1.2\n",
      "joblib                  1.1.1\n",
      "jsonschema              4.17.3\n",
      "jupyter_client          7.4.9\n",
      "jupyter_core            4.11.2\n",
      "jupyter-server          1.23.4\n",
      "jupyterlab-pygments     0.1.2\n",
      "keras                   2.10.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.4.4\n",
      "Markdown                3.4.1\n",
      "MarkupSafe              2.1.1\n",
      "matplotlib              3.5.3\n",
      "matplotlib-inline       0.1.6\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.3.1\n",
      "mkl-random              1.2.2\n",
      "mkl-service             2.4.0\n",
      "multidict               6.0.2\n",
      "nbclassic               0.5.2\n",
      "nbclient                0.5.13\n",
      "nbconvert               6.4.4\n",
      "nbformat                5.7.0\n",
      "nest-asyncio            1.5.6\n",
      "notebook                6.5.2\n",
      "notebook_shim           0.2.2\n",
      "numpy                   1.21.5\n",
      "oauthlib                3.2.1\n",
      "opencv-python           4.7.0.72\n",
      "opt-einsum              3.3.0\n",
      "packaging               22.0\n",
      "pandas                  1.3.5\n",
      "pandocfilters           1.5.0\n",
      "parso                   0.8.3\n",
      "pickleshare             0.7.5\n",
      "Pillow                  9.5.0\n",
      "pip                     22.3.1\n",
      "pkgutil_resolve_name    1.3.10\n",
      "prometheus-client       0.14.1\n",
      "prompt-toolkit          3.0.36\n",
      "protobuf                3.20.3\n",
      "psutil                  5.9.0\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.21\n",
      "Pygments                2.11.2\n",
      "PyJWT                   2.4.0\n",
      "pyOpenSSL               23.0.0\n",
      "pyparsing               3.0.9\n",
      "pyrsistent              0.18.0\n",
      "PySocks                 1.7.1\n",
      "python-dateutil         2.8.2\n",
      "pytz                    2023.3\n",
      "pywin32                 305.1\n",
      "pywinpty                2.0.10\n",
      "pyzmq                   23.2.0\n",
      "requests                2.28.1\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "scikit-learn            1.0.2\n",
      "scipy                   1.7.3\n",
      "seaborn                 0.12.2\n",
      "Send2Trash              1.8.0\n",
      "setuptools              65.6.3\n",
      "six                     1.16.0\n",
      "sniffio                 1.2.0\n",
      "soupsieve               2.3.2.post1\n",
      "tensorboard             2.10.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.1\n",
      "tensorflow              2.10.0\n",
      "tensorflow-estimator    2.10.0\n",
      "termcolor               2.1.0\n",
      "terminado               0.17.1\n",
      "testpath                0.6.0\n",
      "threadpoolctl           2.2.0\n",
      "tornado                 6.2\n",
      "traitlets               5.7.1\n",
      "typing_extensions       4.4.0\n",
      "urllib3                 1.26.14\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        0.58.0\n",
      "Werkzeug                2.2.2\n",
      "wheel                   0.38.4\n",
      "win-inet-pton           1.1.0\n",
      "wincertstore            0.2\n",
      "wrapt                   1.14.1\n",
      "yarl                    1.8.1\n",
      "zipp                    3.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8990fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import time\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('C:/Users/USER/Downloads/shape_predictor_68_face_landmarks (1).dat/shape_predictor_68_face_landmarks (1).dat')\n",
    "\n",
    "model = load_model('Downloads/learning_data_model.h5')\n",
    "model.summery()\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "  x1, y1 = np.amin(eye_points, axis=0)\n",
    "  x2, y2 = np.amax(eye_points, axis=0)\n",
    "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "  w = (x2 - x1) * 1.2\n",
    "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "  margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "  return eye_img, eye_rect\n",
    "\n",
    "# main\n",
    "cap = cv2.VideoCapture('C:/Users/USER/Downloads/blink_mp4.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img_ori = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "  img = img_ori.copy()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  faces = detector(gray)\n",
    "\n",
    "  for face in faces:\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    cv2.imshow('l', eye_img_l)\n",
    "    cv2.imshow('r', eye_img_r)\n",
    "\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # visualize\n",
    "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    if state_l <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:    \n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "     \n",
    "    if state_r <= '0' :\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,0,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "\n",
    "  cv2.imshow('result', img)\n",
    "  if cv2.waitKey(1) == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed5acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
